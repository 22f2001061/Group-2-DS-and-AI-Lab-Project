{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collation and Yolo Model Training\n",
        "- In this colab we create a master dataset and tune a Yolov8n model"
      ],
      "metadata": {
        "id": "9VhTUHjJ8eVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up reproducibility\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "SEED_VALUE = 42\n",
        "\n",
        "random.seed(SEED_VALUE)\n",
        "\n",
        "np.random.seed(SEED_VALUE)\n",
        "\n",
        "torch.manual_seed(SEED_VALUE)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED_VALUE)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
        "\n",
        "print(f\"‚úÖ All libraries seeded with value: {SEED_VALUE}\")\n",
        "print(f\"   PyTorch CUDA deterministic: {torch.backends.cudnn.deterministic}\")"
      ],
      "metadata": {
        "id": "t0qri0u-BeJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "youtube_frames_path = \"/content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames\"\n",
        "\n",
        "if os.path.exists(youtube_frames_path):\n",
        "    print(f\"‚úÖ Google Drive mounted and YouTube frames folder found at: {youtube_frames_path}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è ERROR: Could not find YouTube frames folder at: {youtube_frames_path}\")\n",
        "    print(\"Please double-check the path and try mounting again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArRgJGc7sMdA",
        "outputId": "2f44efdb-deef-40f5-ef65-ece438e34294"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted and YouTube frames folder found at: /content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3de84e5",
        "outputId": "ded95fbd-be71-4432-e04f-b91033a05910"
      },
      "source": [
        "!pip install ultralytics -q\n",
        "print(\"‚úÖ Ultralytics installed.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ultralytics installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Master Dataset"
      ],
      "metadata": {
        "id": "v77mzzt688wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "#unzipping filtered dataset -coco\n",
        "coco_zip_path = \"/content/drive/MyDrive/VisionAssist-Dataset/filtered_coco_data.zip\"\n",
        "unzip_destination = \"temp_coco_unzipped\"\n",
        "\n",
        "if not os.path.exists(coco_zip_path):\n",
        "    print(f\"‚ö†Ô∏è ERROR: Cannot find the zip file at: {coco_zip_path}\")\n",
        "    print(\"Please make sure the file exists in your Google Drive.\")\n",
        "else:\n",
        "    #Unzip the File\n",
        "    print(f\"Unzipping '{os.path.basename(coco_zip_path)}' to '{unzip_destination}'...\")\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    os.makedirs(unzip_destination, exist_ok=True)\n",
        "    try:\n",
        "        with zipfile.ZipFile(coco_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(unzip_destination)\n",
        "        print(\"‚úÖ Unzipping complete.\")\n",
        "\n",
        "        potential_coco_data_folder = os.path.join(unzip_destination, \"yolo_data\")\n",
        "        if os.path.exists(os.path.join(potential_coco_data_folder, \"images\")):\n",
        "             actual_coco_data_folder = potential_coco_data_folder\n",
        "             print(f\"Found COCO data inside '{actual_coco_data_folder}'\")\n",
        "        elif os.path.exists(os.path.join(unzip_destination, \"images\")):\n",
        "             actual_coco_data_folder = unzip_destination\n",
        "             print(f\"Found COCO data directly inside '{actual_coco_data_folder}'\")\n",
        "        else:\n",
        "             actual_coco_data_folder = None\n",
        "             print(f\"‚ö†Ô∏è ERROR: Could not find 'images' and 'labels' folders within '{unzip_destination}'.\")\n",
        "\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"‚ö†Ô∏è ERROR: The file '{coco_zip_path}' is not a valid zip file or is corrupted.\")\n",
        "        actual_coco_data_folder = None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è An error occurred during unzipping: {e}\")\n",
        "        actual_coco_data_folder = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZwL_PeQHF53",
        "outputId": "4bd46eec-ad1d-4f4f-ae78-1ab55ec4ab02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping 'filtered_coco_data.zip' to 'temp_coco_unzipped'...\n",
            "‚úÖ Unzipping complete.\n",
            "Found COCO data directly inside 'temp_coco_unzipped'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "if 'actual_coco_data_folder' not in locals() or actual_coco_data_folder is None:\n",
        "    print(\"‚ö†Ô∏è ERROR: 'actual_coco_data_folder' is not defined. Please run Cell 1 successfully first.\")\n",
        "else:\n",
        "    coco_data_folder = actual_coco_data_folder # Use the path found after unzipping\n",
        "    youtube_frames_folder = \"/content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames\"\n",
        "    master_dataset_folder = \"master_dataset\"\n",
        "    master_images_folder = os.path.join(master_dataset_folder, \"images\")\n",
        "\n",
        "\n",
        "    # create master folder\n",
        "    print(f\"\\nCreating master images folder at '{master_images_folder}'...\")\n",
        "    os.makedirs(master_images_folder, exist_ok=True)\n",
        "\n",
        "    coco_images_path = os.path.join(coco_data_folder, \"images\")\n",
        "\n",
        "    # only check for image path\n",
        "    if os.path.exists(coco_images_path):\n",
        "        print(f\"Copying images from '{coco_images_path}' to '{master_images_folder}'...\")\n",
        "        # Using copytree with dirs_exist_ok=True merges contents\n",
        "        shutil.copytree(coco_images_path, master_images_folder, dirs_exist_ok=True)\n",
        "        print(\"COCO images copied.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è ERROR: Could not find COCO 'images' folder in '{coco_data_folder}'.\")\n",
        "\n",
        "    # copy yt frames\n",
        "    if os.path.exists(youtube_frames_folder):\n",
        "        print(f\"Copying images from '{youtube_frames_folder}' to '{master_images_folder}'...\")\n",
        "        copied_yt_count = 0\n",
        "        for filename in os.listdir(youtube_frames_folder):\n",
        "            source_file = os.path.join(youtube_frames_folder, filename)\n",
        "            if os.path.isfile(source_file) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                destination_file = os.path.join(master_images_folder, filename)\n",
        "                shutil.copy2(source_file, destination_file)\n",
        "                copied_yt_count += 1\n",
        "        print(f\"Copied {copied_yt_count} YouTube frame images.\")\n",
        "    else:\n",
        "         print(f\"‚ö†Ô∏è Skipping YouTube frames copy as folder '{youtube_frames_folder}' was not found.\")\n",
        "\n",
        "\n",
        "    # verification\n",
        "    print(\"\\n--- Verification ---\")\n",
        "    try:\n",
        "        num_master_images = len(os.listdir(master_images_folder))\n",
        "        print(f\"Total images in '{master_images_folder}': {num_master_images}\")\n",
        "        print(\"\\n‚úÖ Master dataset folder with images created successfully.\")\n",
        "        print(f\"You can now point your YOLOv8 annotation script to the '{master_images_folder}'.\")\n",
        "        print(f\"Make sure your annotation script saves the *new* label files into a separate 'labels' folder (e.g., 'master_dataset/labels').\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Verification failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2nfarsqIk7I",
        "outputId": "52b59e17-68d8-4a3d-ab4e-442e7ddfef8b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating master images folder at 'master_dataset/images'...\n",
            "Copying images from 'temp_coco_unzipped/images' to 'master_dataset/images'...\n",
            "COCO images copied.\n",
            "Copying images from '/content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames' to 'master_dataset/images'...\n",
            "Copied 2138 YouTube frame images.\n",
            "\n",
            "--- Verification ---\n",
            "Total images in 'master_dataset/images': 7138\n",
            "\n",
            "‚úÖ Master dataset folder with images created successfully.\n",
            "You can now point your YOLOv8 annotation script to the 'master_dataset/images'.\n",
            "Make sure your annotation script saves the *new* label files into a separate 'labels' folder (e.g., 'master_dataset/labels').\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for Annotation\n",
        "\n",
        "!pip install ultralytics -q\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from tqdm import tqdm # Progress bar\n",
        "\n",
        "print(\"‚úÖ Ultralytics installed.\")\n",
        "\n",
        "MASTER_IMAGES_FOLDER = \"/content/master_dataset/images\"\n",
        "MASTER_LABELS_FOLDER = \"/content/master_dataset/labels\"\n",
        "\n",
        "\n",
        "os.makedirs(MASTER_LABELS_FOLDER, exist_ok=True)\n",
        "print(f\"Labels will be saved to: {MASTER_LABELS_FOLDER}\")\n",
        "\n",
        "\n",
        "ANNOTATION_MODEL_NAME = 'yolov8n.pt'\n",
        "print(f\"Loading annotation model: {ANNOTATION_MODEL_NAME}...\")\n",
        "annotation_model = YOLO(ANNOTATION_MODEL_NAME)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "annotation_model.to(DEVICE)\n",
        "print(f\"Model loaded successfully on {DEVICE}.\")\n",
        "\n",
        "\n",
        "print(\"Will save labels for ALL detected COCO classes (0-79) using their original IDs.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    # Gets all image files from the master images folder\n",
        "    image_files = [f for f in os.listdir(MASTER_IMAGES_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"\\nFound {len(image_files)} total images to annotate in {MASTER_IMAGES_FOLDER}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- ERROR ---\")\n",
        "    print(f\"Could not find the image folder: {MASTER_IMAGES_FOLDER}\")\n",
        "    print(\"Please ensure the master_dataset folder was created correctly.\")\n",
        "    image_files = [] # Prevent crash\n",
        "\n",
        "\n",
        "annotation_count = 0 # Counter for images where labels were successfully generated\n",
        "\n",
        "if image_files: # Only proceed if images were found\n",
        "    # Loop through every image file with a progress bar\n",
        "    for image_name in tqdm(image_files, desc=\"Annotating ALL Images\"):\n",
        "        image_path = os.path.join(MASTER_IMAGES_FOLDER, image_name)\n",
        "\n",
        "        # Define the path where the label file should be saved\n",
        "        label_name = os.path.splitext(image_name)[0] + \".txt\"\n",
        "        label_path = os.path.join(MASTER_LABELS_FOLDER, label_name)\n",
        "\n",
        "\n",
        "        # Predicts objects in the current image using the loaded model\n",
        "        results = annotation_model.predict(image_path, save=False, verbose=False, conf=0.25)\n",
        "\n",
        "        #  Convert Results to YOLO TXT Format and Save\n",
        "        # Checks if the prediction found any objects\n",
        "        if results and len(results[0].boxes) > 0:\n",
        "            lines_written = 0\n",
        "            # Opens the corresponding label file for writing (overwrites if it exists)\n",
        "            with open(label_path, 'w') as f:\n",
        "                # Iterates through each detected object (box)\n",
        "                for box in results[0].boxes:\n",
        "                    # Gets the original COCO class ID (0-79)\n",
        "                    coco_class_id = int(box.cls)\n",
        "\n",
        "                    # Gets normalized coordinates [center_x, center_y, width, height]\n",
        "                    x_center, y_center, width, height = box.xywhn[0].tolist()\n",
        "\n",
        "                    # Writes the label line using the original COCO ID\n",
        "                    f.write(f\"{coco_class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "                    lines_written += 1 # Count line written\n",
        "\n",
        "            # If we wrote labels to the file, increment the success counter\n",
        "            if lines_written > 0:\n",
        "                 annotation_count += 1\n",
        "            # If no objects were detected (lines_written == 0),\n",
        "            # but an empty file was created, remove the empty file.\n",
        "            elif os.path.exists(label_path):\n",
        "                 try: # Add error handling just in case\n",
        "                     if os.path.getsize(label_path) == 0:\n",
        "                          os.remove(label_path)\n",
        "                 except OSError:\n",
        "                      pass # Ignore error if file is already gone etc.\n",
        "\n",
        "        # else: # No detections made by the model for this image\n",
        "            # No label file needed or created.\n",
        "\n",
        "    # final summary\n",
        "    print(f\"\\n--- Annotation Summary ---\")\n",
        "    print(f\"Processed {len(image_files)} images.\")\n",
        "    print(f\"Generated or overwrote labels for {annotation_count} images.\")\n",
        "    print(f\"Labels were saved using original COCO class IDs (0-79).\")\n",
        "    print(f\"All labels are now saved in: {MASTER_LABELS_FOLDER}\")\n",
        "else:\n",
        "    # Message if the image folder was empty or not found\n",
        "    print(\"No images found to process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtqfMo1VZPdx",
        "outputId": "ff909da0-b1de-487d-b598-7d1bd4ce2948"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ Ultralytics installed.\n",
            "Labels will be saved to: /content/master_dataset/labels\n",
            "Loading annotation model: yolov8n.pt...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 359.4MB/s 0.0s\n",
            "Model loaded successfully on cuda.\n",
            "Will save labels for ALL detected COCO classes (0-79) using their original IDs.\n",
            "\n",
            "Found 7138 total images to annotate in /content/master_dataset/images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Annotating ALL Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7138/7138 [02:15<00:00, 52.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Annotation Summary ---\n",
            "Processed 7138 images.\n",
            "Generated or overwrote labels for 7102 images.\n",
            "Labels were saved using original COCO class IDs (0-79).\n",
            "All labels are now saved in: /content/master_dataset/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6970a2ab",
        "outputId": "761034ea-79e5-4161-dec5-2d70e3c94d6f",
        "collapsed": true
      },
      "source": [
        "!pip install supervision numpy opencv-python lap\n",
        "\n",
        "print(\"‚úÖ Necessary libraries for ByteTrack and tracking installed.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision\n",
            "  Downloading supervision-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Collecting lap\n",
            "  Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (1.16.3)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (6.0.3)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision) (11.3.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.26.1-py3-none-any.whl (207 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/207.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lap, supervision\n",
            "Successfully installed lap-0.5.12 supervision-0.26.1\n",
            "‚úÖ Necessary libraries for ByteTrack and tracking installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the dataset"
      ],
      "metadata": {
        "id": "dniQtoyyg7LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "MASTER_DATASET_FOLDER = \"master_dataset\" # Folder containing 'images' and 'labels'\n",
        "OUTPUT_FOLDER = \"split_dataset\"        # New folder where 'train', 'valid', 'test' will be created\n",
        "TRAIN_RATIO = 0.70                     # 70% for training\n",
        "VALID_RATIO = 0.20                     # 20% for validation\n",
        "TEST_RATIO = 0.10                      # 10% for testing\n",
        "\n",
        "# Sanity Check\n",
        "if abs(TRAIN_RATIO + VALID_RATIO + TEST_RATIO - 1.0) > 1e-6:\n",
        "    print(\"‚ö†Ô∏è ERROR: Ratios must add up to 1.0\")\n",
        "else:\n",
        "    # Define paths\n",
        "    images_input_dir = os.path.join(MASTER_DATASET_FOLDER, \"images\")\n",
        "    labels_input_dir = os.path.join(MASTER_DATASET_FOLDER, \"labels\")\n",
        "\n",
        "    train_images_dir = os.path.join(OUTPUT_FOLDER, \"train\", \"images\")\n",
        "    train_labels_dir = os.path.join(OUTPUT_FOLDER, \"train\", \"labels\")\n",
        "    valid_images_dir = os.path.join(OUTPUT_FOLDER, \"valid\", \"images\")\n",
        "    valid_labels_dir = os.path.join(OUTPUT_FOLDER, \"valid\", \"labels\")\n",
        "    test_images_dir = os.path.join(OUTPUT_FOLDER, \"test\", \"images\")\n",
        "    test_labels_dir = os.path.join(OUTPUT_FOLDER, \"test\", \"labels\")\n",
        "\n",
        "    # Create output directories\n",
        "    print(f\"Creating output directories in '{OUTPUT_FOLDER}'...\")\n",
        "    os.makedirs(train_images_dir, exist_ok=True)\n",
        "    os.makedirs(train_labels_dir, exist_ok=True)\n",
        "    os.makedirs(valid_images_dir, exist_ok=True)\n",
        "    os.makedirs(valid_labels_dir, exist_ok=True)\n",
        "    os.makedirs(test_images_dir, exist_ok=True)\n",
        "    os.makedirs(test_labels_dir, exist_ok=True)\n",
        "\n",
        "    # Get List of All Image Files\n",
        "    try:\n",
        "        all_images = [f for f in os.listdir(images_input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        if not all_images:\n",
        "             print(f\"‚ö†Ô∏è ERROR: No images found in '{images_input_dir}'.\")\n",
        "        else:\n",
        "             print(f\"Found {len(all_images)} images in '{images_input_dir}'.\")\n",
        "             # shuffle the images\n",
        "             random.shuffle(all_images)\n",
        "\n",
        "             # Calculate Split Indices\n",
        "             total_images = len(all_images)\n",
        "             train_end_idx = int(total_images * TRAIN_RATIO)\n",
        "             valid_end_idx = train_end_idx + int(total_images * VALID_RATIO)\n",
        "             # The rest go to test\n",
        "\n",
        "             # Define Splits\n",
        "             train_files = all_images[:train_end_idx]\n",
        "             valid_files = all_images[train_end_idx:valid_end_idx]\n",
        "             test_files = all_images[valid_end_idx:]\n",
        "\n",
        "             print(f\"Splitting into: {len(train_files)} Train, {len(valid_files)} Valid, {len(test_files)} Test\")\n",
        "\n",
        "             # Function to Copy Files\n",
        "             def copy_files(file_list, source_img_dir, source_lbl_dir, dest_img_dir, dest_lbl_dir):\n",
        "                 copied_count = 0\n",
        "                 for filename in tqdm(file_list, desc=f\"Copying to {os.path.basename(dest_img_dir)}\"):\n",
        "                     # Copy Image\n",
        "                     source_image_path = os.path.join(source_img_dir, filename)\n",
        "                     dest_image_path = os.path.join(dest_img_dir, filename)\n",
        "                     if os.path.exists(source_image_path):\n",
        "                         shutil.copy2(source_image_path, dest_image_path)\n",
        "\n",
        "                         # Copy Corresponding Label (if it exists)\n",
        "                         label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "                         source_label_path = os.path.join(source_lbl_dir, label_filename)\n",
        "                         dest_label_path = os.path.join(dest_lbl_dir, label_filename)\n",
        "                         if os.path.exists(source_label_path):\n",
        "                             shutil.copy2(source_label_path, dest_label_path)\n",
        "                         # else:\n",
        "                         #     print(f\"Warning: Label file not found for {filename}\") # Optional warning\n",
        "                         copied_count += 1\n",
        "                 return copied_count\n",
        "\n",
        "             # Perform the Copying\n",
        "             print(\"\\nCopying training files...\")\n",
        "             train_copied = copy_files(train_files, images_input_dir, labels_input_dir, train_images_dir, train_labels_dir)\n",
        "             print(f\"Copied {train_copied} training images and labels.\")\n",
        "\n",
        "             print(\"\\nCopying validation files...\")\n",
        "             valid_copied = copy_files(valid_files, images_input_dir, labels_input_dir, valid_images_dir, valid_labels_dir)\n",
        "             print(f\"Copied {valid_copied} validation images and labels.\")\n",
        "\n",
        "             print(\"\\nCopying test files...\")\n",
        "             test_copied = copy_files(test_files, images_input_dir, labels_input_dir, test_images_dir, test_labels_dir)\n",
        "             print(f\"Copied {test_copied} test images and labels.\")\n",
        "\n",
        "             print(\"\\n‚úÖ Dataset splitting complete!\")\n",
        "             print(f\"Split dataset is ready in the '{OUTPUT_FOLDER}' folder.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"--- ERROR ---\")\n",
        "        print(f\"Could not find the image folder: {images_input_dir}\")\n",
        "        print(\"Please ensure the master_dataset folder exists and contains images.\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- An unexpected error occurred: {e} ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbvzTBBYg--_",
        "outputId": "a4b6b7c6-c096-4e15-f92d-484241d9f28e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output directories in 'split_dataset'...\n",
            "Found 7138 images in 'master_dataset/images'.\n",
            "Splitting into: 4996 Train, 1427 Valid, 715 Test\n",
            "\n",
            "Copying training files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying to images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4996/4996 [00:01<00:00, 2781.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 4996 training images and labels.\n",
            "\n",
            "Copying validation files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying to images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1427/1427 [00:00<00:00, 2589.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 1427 validation images and labels.\n",
            "\n",
            "Copying test files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying to images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 715/715 [00:00<00:00, 810.98it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 715 test images and labels.\n",
            "\n",
            "‚úÖ Dataset splitting complete!\n",
            "Split dataset is ready in the 'split_dataset' folder.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting this in drive.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "temp_dataset_folder = '/content/split_dataset'\n",
        "permanent_dataset_folder = '/content/drive/My Drive/VisionAssist-Dataset/split_dataset'\n",
        "\n",
        "if os.path.exists(permanent_dataset_folder):\n",
        "    print(f\"Dataset already exists at: {permanent_dataset_folder}\")\n",
        "else:\n",
        "    print(f\"Copying temporary dataset from {temp_dataset_folder} to {permanent_dataset_folder}...\")\n",
        "    try:\n",
        "        shutil.copytree(temp_dataset_folder, permanent_dataset_folder)\n",
        "        print(\"‚úÖ Successfully created permanent dataset in Google Drive.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error copying dataset: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1c0E8Sdkv1L",
        "outputId": "4377ae7a-605f-42bb-db60-23c3626c225d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already exists at: /content/drive/My Drive/VisionAssist-Dataset/split_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a data.yaml file\n"
      ],
      "metadata": {
        "id": "w1dNIFrchT9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile coco_custom_data.yaml\n",
        "# YAML configuration file for YOLOv8 training\n",
        "\n",
        "# Dataset paths: Relative paths to the split dataset folder\n",
        "# Assumes this yaml file is in /content/ and the data is in /content/split_dataset/\n",
        "train: ./split_dataset/train/images\n",
        "val: ./split_dataset/valid/images\n",
        "test: ./split_dataset/test/images # Optional: path to test images\n",
        "\n",
        "# Number of classes\n",
        "# Must be 80 since we used original COCO IDs during annotation\n",
        "nc: 80\n",
        "\n",
        "# Class names\n",
        "# Must be the standard 80 COCO class names in the correct order (0-79)\n",
        "names:\n",
        "  0: person\n",
        "  1: bicycle\n",
        "  2: car\n",
        "  3: motorcycle\n",
        "  4: airplane\n",
        "  5: bus\n",
        "  6: train\n",
        "  7: truck\n",
        "  8: boat\n",
        "  9: traffic light\n",
        "  10: fire hydrant\n",
        "  11: stop sign\n",
        "  12: parking meter\n",
        "  13: bench\n",
        "  14: bird\n",
        "  15: cat\n",
        "  16: dog\n",
        "  17: horse\n",
        "  18: sheep\n",
        "  19: cow\n",
        "  20: elephant\n",
        "  21: bear\n",
        "  22: zebra\n",
        "  23: giraffe\n",
        "  24: backpack\n",
        "  25: umbrella\n",
        "  26: handbag\n",
        "  27: tie\n",
        "  28: suitcase\n",
        "  29: frisbee\n",
        "  30: skis\n",
        "  31: snowboard\n",
        "  32: sports ball\n",
        "  33: kite\n",
        "  34: baseball bat\n",
        "  35: baseball glove\n",
        "  36: skateboard\n",
        "  37: surfboard\n",
        "  38: tennis racket\n",
        "  39: bottle\n",
        "  40: wine glass\n",
        "  41: cup\n",
        "  42: fork\n",
        "  43: knife\n",
        "  44: spoon\n",
        "  45: bowl\n",
        "  46: banana\n",
        "  47: apple\n",
        "  48: sandwich\n",
        "  49: orange\n",
        "  50: broccoli\n",
        "  51: carrot\n",
        "  52: hot dog\n",
        "  53: pizza\n",
        "  54: donut\n",
        "  55: cake\n",
        "  56: chair\n",
        "  57: couch\n",
        "  58: potted plant\n",
        "  59: bed\n",
        "  60: dining table\n",
        "  61: toilet\n",
        "  62: tv\n",
        "  63: laptop\n",
        "  64: mouse\n",
        "  65: remote\n",
        "  66: keyboard\n",
        "  67: cell phone\n",
        "  68: microwave\n",
        "  69: oven\n",
        "  70: toaster\n",
        "  71: sink\n",
        "  72: refrigerator\n",
        "  73: book\n",
        "  74: clock\n",
        "  75: vase\n",
        "  76: scissors\n",
        "  77: teddy bear\n",
        "  78: hair drier\n",
        "  79: toothbrush"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIkR_YfIhWRu",
        "outputId": "c736e7d8-2442-4fe2-dd69-858e185fafe7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting coco_custom_data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86effd82",
        "outputId": "49dac7d8-b8dc-478b-86b2-f9c5b3b3b8db"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "colab_file_path = 'coco_custom_data.yaml'\n",
        "\n",
        "# Path where you want to save the file in Google Drive\n",
        "\n",
        "drive_save_folder = '/content/drive/My Drive/VisionAssist-Dataset/'\n",
        "drive_save_path = os.path.join(drive_save_folder, os.path.basename(colab_file_path))\n",
        "\n",
        "# --- Mount Drive (if not already mounted) ---\n",
        "try:\n",
        "    if not os.path.exists('/content/drive/My Drive'):\n",
        "         print(\"Mounting Google Drive...\")\n",
        "         drive.mount('/content/drive')\n",
        "    else:\n",
        "         print(\"Google Drive already mounted.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting drive: {e}\")\n",
        "\n",
        "# --- Check if File Exists in Colab ---\n",
        "if not os.path.exists(colab_file_path):\n",
        "    print(f\"--- ERROR: File not found in Colab at '{colab_file_path}' ---\")\n",
        "    print(\"Please ensure the 'coco_custom_data.yaml' file was created successfully.\")\n",
        "else:\n",
        "    # --- Create Save Directory in Drive ---\n",
        "    print(f\"Ensuring save directory exists: {drive_save_folder}\")\n",
        "    os.makedirs(drive_save_folder, exist_ok=True)\n",
        "\n",
        "    # --- Copy the File ---\n",
        "    print(f\"Copying '{os.path.basename(colab_file_path)}' to '{drive_save_path}'...\")\n",
        "    try:\n",
        "        shutil.copy(colab_file_path, drive_save_path)\n",
        "        print(\"‚úÖ File successfully saved to Google Drive.\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- ERROR saving file to Drive: {e} ---\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive already mounted.\n",
            "Ensuring save directory exists: /content/drive/My Drive/VisionAssist-Dataset/\n",
            "Copying 'coco_custom_data.yaml' to '/content/drive/My Drive/VisionAssist-Dataset/coco_custom_data.yaml'...\n",
            "‚úÖ File successfully saved to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning YOLOV8N"
      ],
      "metadata": {
        "id": "_gUemh0Ohi81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Constants\n",
        "WORKERS = max(2, os.cpu_count() // 2)\n",
        "N_TRIALS = 15\n",
        "EPOCHS_PER_TRIAL = 15\n",
        "PATIENCE = 3\n",
        "\n",
        "print(f\"--- Using global SEED_VALUE: {SEED_VALUE} ---\")\n",
        "\n",
        "def objective(trial):\n",
        "    try:\n",
        "         # learning rate\n",
        "        lr0 = trial.suggest_float(\"lr0\", 1e-5, 1e-3, log=True)\n",
        "        # optimization\n",
        "        # Weight decay helps prevent overfitting.\n",
        "        weight_decay = trial.suggest_float(\"weight_decay\", 5e-5, 5e-3, log=True)\n",
        "        # testing different optimizers\n",
        "        optimizer = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"SGD\"])\n",
        "        degrees = trial.suggest_float(\"degrees\", 0.0, 5.0)\n",
        "        # data augmentation\n",
        "        translate = trial.suggest_float(\"translate\", 0.0, 0.1)  # less rotation\n",
        "        scale = trial.suggest_float(\"scale\", 0.7, 0.9)    # less translation\n",
        "        hsv_s = trial.suggest_float(\"hsv_s\", 0.4, 0.7)     # similar scale\n",
        "        hsv_v = trial.suggest_float(\"hsv_v\", 0.4, 0.7)\n",
        "        fliplr = trial.suggest_float(\"fliplr\", 0.0, 0.5)\n",
        "\n",
        "        # create and train the model\n",
        "        model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "        # Start training\n",
        "        model.train(\n",
        "            data=\"coco_custom_data.yaml\",\n",
        "            freeze=True,\n",
        "            epochs=EPOCHS_PER_TRIAL,\n",
        "            patience=PATIENCE,\n",
        "            imgsz=640,\n",
        "            batch=64,\n",
        "            workers=WORKERS,\n",
        "            device=0,\n",
        "            project=\"optuna_yolo_fine_tune\",\n",
        "            name=f\"trial_{trial.number}\",\n",
        "\n",
        "            # Hyperparameters from Optuna\n",
        "            optimizer=optimizer,\n",
        "            lr0=lr0,\n",
        "            weight_decay=weight_decay,\n",
        "            degrees=degrees,\n",
        "            translate=translate,\n",
        "            scale=scale,\n",
        "            hsv_s=hsv_s,\n",
        "            hsv_v=hsv_v,\n",
        "            fliplr=fliplr,\n",
        "\n",
        "            verbose=False,\n",
        "            amp=True,\n",
        "            plots=False,\n",
        "\n",
        "\n",
        "            seed=SEED_VALUE,\n",
        "            deterministic=True\n",
        "\n",
        "        )\n",
        "\n",
        "        metrics = getattr(model, \"metrics\", {})\n",
        "        mAP50 = getattr(metrics, \"results_dict\", {}).get(\"metrics/mAP50(B)\", 0.0)\n",
        "\n",
        "        return mAP50\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Trial {trial.number} failed with error: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Progress tracking\n",
        "start_time = time.time()\n",
        "\n",
        "def callback(study, trial):\n",
        "    elapsed = time.time() - start_time\n",
        "    done = len(study.trials)\n",
        "    avg_time = elapsed / done if done > 0 else 0\n",
        "    remaining = (N_TRIALS - done) * avg_time\n",
        "    print(f\"\\nüß† Trial {done}/{N_TRIALS} completed\")\n",
        "    print(f\"   ‚è± Elapsed: {elapsed/60:.2f} min | Est. remaining: {remaining/60:.2f} min\")\n",
        "    print(f\"   üìà Best mAP50 so far: {study.best_value:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Define a seeded sampler for Optuna\n",
        "sampler = optuna.samplers.TPESampler(seed=SEED_VALUE)\n",
        "\n",
        "print(f\"Starting Optuna optimization... Searching for {N_TRIALS} trials with seed {SEED_VALUE}.\")\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials=N_TRIALS, callbacks=[callback])\n",
        "\n",
        "# final report\n",
        "total_time = (time.time() - start_time) / 60\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"üèÜ BEST TRIAL SUMMARY üèÜ\")\n",
        "print(\"=\"*30)\n",
        "print(f\"   üïí Total time: {total_time:.2f} min\")\n",
        "print(f\"   üìä Best mAP50: {study.best_trial.value:.4f}\")\n",
        "print(\"   ‚öôÔ∏è Best Params:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"      {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_wKi4XfhkrD",
        "outputId": "bb90b73c-aa99-46a9-ee58-d1580384954f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-04 15:39:05,585] A new study created in memory with name: no-name-b324e2dd-162c-4078-a881-cc4b4bcb0c69\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Optuna optimization... Searching for 15 trials.\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=2.02234428260504, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.14726144774341782, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6033093626797703, hsv_v=0.6444198248957093, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00012889634912898807, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8008608451780083, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.09068219543990846, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005177406727578624, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 150.2MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 293.3MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2018.0¬±1056.0 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 2.4Kit/s 2.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/split_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 769.6¬±571.0 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 1.1Kit/s 1.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/split_dataset/valid/labels.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00012889634912898807, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005177406727578624), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_0\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.12G     0.9916      1.118        1.1         56        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.1s\n",
            "                   all       1427      10955      0.802      0.791      0.882      0.783\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.73G     0.9663      1.036      1.084         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.7s\n",
            "                   all       1427      10955      0.822      0.792      0.887      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.84G     0.9714       1.03      1.082         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.2s\n",
            "                   all       1427      10955      0.814      0.801      0.884      0.774\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.49G     0.9505      1.006      1.069        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.2s\n",
            "                   all       1427      10955      0.815      0.791      0.883      0.776\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.097 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_0/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_0/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_0/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.5it/s 7.8s\n",
            "                   all       1427      10955      0.803      0.788      0.882      0.783\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-04 15:45:29,721] Trial 0 finished with value: 0.8820322074102609 and parameters: {'lr0': 0.00012889634912898807, 'weight_decay': 0.0005177406727578624, 'optimizer': 'SGD', 'degrees': 2.02234428260504, 'translate': 0.09068219543990846, 'scale': 0.8008608451780083, 'hsv_s': 0.6033093626797703, 'hsv_v': 0.6444198248957093, 'fliplr': 0.14726144774341782}. Best is trial 0 with value: 0.8820322074102609.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß† Trial 1/15 completed\n",
            "   ‚è± Elapsed: 6.40 min | Est. remaining: 89.63 min\n",
            "   üìà Best mAP50 so far: 0.8820\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=3.7589273841096356, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.026195651928720587, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.5549357382886335, hsv_v=0.45552370718613133, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1.1715560211053696e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8822242326607416, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05667051099823243, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0002346732908940307, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1475.9¬±675.5 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 5.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 688.5¬±379.9 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 826.7Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=1.1715560211053696e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0002346732908940307), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_1\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      8.91G      1.077      1.156      1.126         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.9s\n",
            "                   all       1427      10955       0.79      0.802      0.875      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.73G      1.048       1.09      1.112         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:09\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.7s\n",
            "                   all       1427      10955      0.804      0.777      0.874      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15       9.5G      1.053      1.088      1.112         72        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 12.4s\n",
            "                   all       1427      10955      0.794      0.799      0.881      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.54G      1.036      1.073      1.104        108        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:10\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.4s\n",
            "                   all       1427      10955      0.804      0.783      0.881      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15      10.2G       1.03      1.063      1.097         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.7s\n",
            "                   all       1427      10955        0.8      0.786      0.878      0.733\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15      8.26G      0.976      1.105      1.084         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 12.6s\n",
            "                   all       1427      10955      0.744       0.72      0.814      0.666\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 3, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "6 epochs completed in 0.146 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_1/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_1/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_1/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.4it/s 8.6s\n",
            "                   all       1427      10955      0.792      0.799      0.882      0.744\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-04 15:54:26,862] Trial 1 finished with value: 0.8817609013423634 and parameters: {'lr0': 1.1715560211053696e-05, 'weight_decay': 0.0002346732908940307, 'optimizer': 'SGD', 'degrees': 3.7589273841096356, 'translate': 0.05667051099823243, 'scale': 0.8822242326607416, 'hsv_s': 0.5549357382886335, 'hsv_v': 0.45552370718613133, 'fliplr': 0.026195651928720587}. Best is trial 0 with value: 0.8820322074102609.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß† Trial 2/15 completed\n",
            "   ‚è± Elapsed: 15.35 min | Est. remaining: 99.81 min\n",
            "   üìà Best mAP50 so far: 0.8820\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=3.4309494073626325, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.29663914391283863, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.5015713616723824, hsv_v=0.6904889868433671, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0007394233690239636, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_2, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8812740745371416, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.03154388915068181, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=7.779209090585046e-05, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1406.9¬±598.4 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 7.4Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 450.3¬±249.0 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 1.6Mit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0007394233690239636, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=7.779209090585046e-05), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_2\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.25G      1.092      1.203      1.129         69        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.6s\n",
            "                   all       1427      10955      0.568      0.351      0.383      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.73G      1.113      1.245      1.144         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.1s\n",
            "                   all       1427      10955      0.447      0.286      0.279      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.16G      1.172      1.334      1.182         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.1s\n",
            "                   all       1427      10955      0.389      0.218      0.193      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.54G       1.18      1.362      1.188        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.9s\n",
            "                   all       1427      10955      0.423      0.254      0.236      0.159\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.104 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_2/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_2/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_2/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.3it/s 9.0s\n",
            "                   all       1427      10955      0.569      0.351      0.383      0.274\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-04 16:00:52,036] Trial 2 finished with value: 0.38290680786722536 and parameters: {'lr0': 0.0007394233690239636, 'weight_decay': 7.779209090585046e-05, 'optimizer': 'AdamW', 'degrees': 3.4309494073626325, 'translate': 0.03154388915068181, 'scale': 0.8812740745371416, 'hsv_s': 0.5015713616723824, 'hsv_v': 0.6904889868433671, 'fliplr': 0.29663914391283863}. Best is trial 0 with value: 0.8820322074102609.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 3/15 completed\n",
            "   ‚è± Elapsed: 21.77 min | Est. remaining: 87.10 min\n",
            "   üìà Best mAP50 so far: 0.8820\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=2.5428003252959415, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.46160559439378573, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.4483131748699612, hsv_v=0.6989203013876699, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0008239490553756096, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_3, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.7653966448925787, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.04424908037188261, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.003434810370026725, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1884.7¬±893.7 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 7.5Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 621.6¬±350.2 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 385.3Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0008239490553756096, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.003434810370026725), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_3\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.22G       1.04      1.159      1.111         58        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.2s\n",
            "                   all       1427      10955      0.518      0.319      0.348      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.74G      1.074      1.225      1.135         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.0s\n",
            "                   all       1427      10955      0.468      0.267      0.263      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.51G      1.136      1.317       1.17         71        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.5s\n",
            "                   all       1427      10955      0.323      0.192      0.158      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15       9.5G      1.144      1.344      1.184        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.9s\n",
            "                   all       1427      10955      0.493      0.198      0.209      0.141\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.104 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_3/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_3/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_3/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.6it/s 7.6s\n",
            "                   all       1427      10955       0.52      0.318      0.348      0.259\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 16:07:16,850] Trial 3 finished with value: 0.3481011932494943 and parameters: {'lr0': 0.0008239490553756096, 'weight_decay': 0.003434810370026725, 'optimizer': 'AdamW', 'degrees': 2.5428003252959415, 'translate': 0.04424908037188261, 'scale': 0.7653966448925787, 'hsv_s': 0.4483131748699612, 'hsv_v': 0.6989203013876699, 'fliplr': 0.46160559439378573}. Best is trial 0 with value: 0.8820322074102609.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 4/15 completed\n",
            "   ‚è± Elapsed: 28.19 min | Est. remaining: 77.52 min\n",
            "   üìà Best mAP50 so far: 0.8820\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=3.4483500212153273, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.1295381081846102, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6583696293310719, hsv_v=0.513033167676566, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=3.334127876945122e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_4, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8575619448606786, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.07556802637447274, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.00018759878085511196, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2060.7¬±880.5 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 9.1Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.3¬±0.7 ms, read: 559.5¬±185.6 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 554.0Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=3.334127876945122e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00018759878085511196), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_4\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.72G      1.062      1.149      1.122         61        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 11.9s\n",
            "                   all       1427      10955      0.794      0.788      0.879      0.748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.71G       1.03      1.082      1.106         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.9s\n",
            "                   all       1427      10955       0.81      0.779       0.88      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.47G      1.038      1.072      1.105         71        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.1s\n",
            "                   all       1427      10955      0.795      0.796      0.882      0.745\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.52G      1.017      1.051      1.094        108        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.5s\n",
            "                   all       1427      10955      0.797      0.798      0.886      0.746\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.099 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_4/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_4/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_4/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.3it/s 9.0s\n",
            "                   all       1427      10955      0.792       0.79      0.879      0.748\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 16:13:25,645] Trial 4 finished with value: 0.8785306008521186 and parameters: {'lr0': 3.334127876945122e-05, 'weight_decay': 0.00018759878085511196, 'optimizer': 'SGD', 'degrees': 3.4483500212153273, 'translate': 0.07556802637447274, 'scale': 0.8575619448606786, 'hsv_s': 0.6583696293310719, 'hsv_v': 0.513033167676566, 'fliplr': 0.1295381081846102}. Best is trial 0 with value: 0.8820322074102609.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 5/15 completed\n",
            "   ‚è± Elapsed: 34.33 min | Est. remaining: 68.67 min\n",
            "   üìà Best mAP50 so far: 0.8820\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=2.944331546795463, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.08858123801499751, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.45022176764428434, hsv_v=0.6600076372193737, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=5.974366517785568e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_5, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8255584841249619, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.026566652415048065, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0010906901498095958, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2005.3¬±912.2 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 8.1Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 480.3¬±299.8 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 322.0Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=5.974366517785568e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0010906901498095958), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_5\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.44G      1.048      1.144      1.111         64        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.8s\n",
            "                   all       1427      10955      0.588      0.447      0.497      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.74G      1.005      1.069      1.088         61        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:10\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.3s\n",
            "                   all       1427      10955      0.676      0.563      0.647      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.17G     0.9993      1.036       1.08         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.8it/s 14.4s\n",
            "                   all       1427      10955      0.771      0.679      0.807      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.55G     0.9771      1.007      1.071        106        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.8s\n",
            "                   all       1427      10955      0.755       0.71       0.81      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15      10.2G     0.9676     0.9874      1.063         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.6s\n",
            "                   all       1427      10955      0.783      0.721      0.823      0.677\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15      8.28G       0.88     0.9178      1.041         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.8s\n",
            "                   all       1427      10955      0.757      0.684      0.797      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15      8.16G     0.8541     0.8578      1.034         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.2it/s 1:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.7s\n",
            "                   all       1427      10955      0.745       0.71      0.798      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/15      8.27G     0.8467     0.8484      1.028         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.2it/s 1:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 12.4s\n",
            "                   all       1427      10955      0.727       0.72      0.803      0.661\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 5, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "8 epochs completed in 0.191 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_5/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_5/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_5/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.6it/s 7.6s\n",
            "                   all       1427      10955       0.78      0.726      0.823      0.677\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 16:25:06,134] Trial 5 finished with value: 0.8228123606632736 and parameters: {'lr0': 5.974366517785568e-05, 'weight_decay': 0.0010906901498095958, 'optimizer': 'AdamW', 'degrees': 2.944331546795463, 'translate': 0.026566652415048065, 'scale': 0.8255584841249619, 'hsv_s': 0.45022176764428434, 'hsv_v': 0.6600076372193737, 'fliplr': 0.08858123801499751}. Best is trial 0 with value: 0.8820322074102609.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 6/15 completed\n",
            "   ‚è± Elapsed: 46.01 min | Est. remaining: 69.01 min\n",
            "   üìà Best mAP50 so far: 0.8820\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=1.026172546838315, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.43972425974417323, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6023789462215646, hsv_v=0.6450108866408677, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1.4589954776169732e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_6, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8479919633201535, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.01469212991043145, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0044608484149368886, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1627.7¬±680.9 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 5.3Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.2 ms, read: 406.9¬±227.7 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 312.3Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=1.4589954776169732e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0044608484149368886), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_6\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.76G     0.9815      1.132      1.095         68        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.5s\n",
            "                   all       1427      10955      0.806      0.795      0.885      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.72G     0.9676      1.064      1.086         61        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.1s\n",
            "                   all       1427      10955       0.79       0.81      0.878       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.16G     0.9729      1.062      1.085         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.7s\n",
            "                   all       1427      10955      0.806      0.794      0.885      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.53G     0.9622      1.042       1.08        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.0s\n",
            "                   all       1427      10955      0.805      0.789      0.885      0.796\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.106 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_6/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_6/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_6/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.4it/s 8.4s\n",
            "                   all       1427      10955      0.804      0.797      0.885      0.798\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.5ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 16:31:40,911] Trial 6 finished with value: 0.8850434832978041 and parameters: {'lr0': 1.4589954776169732e-05, 'weight_decay': 0.0044608484149368886, 'optimizer': 'SGD', 'degrees': 1.026172546838315, 'translate': 0.01469212991043145, 'scale': 0.8479919633201535, 'hsv_s': 0.6023789462215646, 'hsv_v': 0.6450108866408677, 'fliplr': 0.43972425974417323}. Best is trial 6 with value: 0.8850434832978041.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 7/15 completed\n",
            "   ‚è± Elapsed: 52.59 min | Est. remaining: 60.10 min\n",
            "   üìà Best mAP50 so far: 0.8850\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=2.055522456917836, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.05149216168003912, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.553322609059306, hsv_v=0.6620887158964566, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=2.536033529399019e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_7, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8833366356754514, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.03601494047070088, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.000684932169580576, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1936.8¬±879.3 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 7.8Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 654.7¬±219.4 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 520.3Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=2.536033529399019e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000684932169580576), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_7\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      8.93G      1.035      1.156      1.106         69        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 11.8s\n",
            "                   all       1427      10955       0.59      0.388      0.424      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.74G     0.9996      1.082      1.086         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.8s\n",
            "                   all       1427      10955      0.621      0.493      0.563      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.65G     0.9898      1.052       1.08         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.1s\n",
            "                   all       1427      10955      0.773      0.728      0.827      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.55G     0.9651       1.02      1.068        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.8it/s 14.2s\n",
            "                   all       1427      10955      0.788      0.739      0.845      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15       9.7G     0.9587          1      1.061         82        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.0s\n",
            "                   all       1427      10955      0.793      0.734      0.845      0.728\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15      8.27G     0.8704     0.9426      1.042         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 11.6s\n",
            "                   all       1427      10955      0.778      0.725      0.826        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15      8.16G     0.8402     0.8785      1.033         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.2it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.9s\n",
            "                   all       1427      10955      0.773      0.738      0.833      0.711\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 4, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "7 epochs completed in 0.168 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_7/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_7/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_7/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.4it/s 8.7s\n",
            "                   all       1427      10955      0.785      0.741      0.845      0.728\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 16:41:58,090] Trial 7 finished with value: 0.8451304931927257 and parameters: {'lr0': 2.536033529399019e-05, 'weight_decay': 0.000684932169580576, 'optimizer': 'AdamW', 'degrees': 2.055522456917836, 'translate': 0.03601494047070088, 'scale': 0.8833366356754514, 'hsv_s': 0.553322609059306, 'hsv_v': 0.6620887158964566, 'fliplr': 0.05149216168003912}. Best is trial 6 with value: 0.8850434832978041.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 8/15 completed\n",
            "   ‚è± Elapsed: 62.88 min | Est. remaining: 55.02 min\n",
            "   üìà Best mAP50 so far: 0.8850\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=3.0436355788344622, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.101100754344642, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6537101657585801, hsv_v=0.4768045506904003, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=2.575193453459791e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_8, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.7143390431304664, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.03435502642011926, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.00010843141695070005, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1930.7¬±851.8 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 8.1Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 589.3¬±193.7 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 446.0Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=2.575193453459791e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00010843141695070005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_8\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      10.2G      1.015      1.107      1.103         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.6s\n",
            "                   all       1427      10955      0.606      0.322      0.367      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.69G     0.9694      1.035       1.08         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:10\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.8s\n",
            "                   all       1427      10955      0.656      0.562       0.64      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.51G     0.9631      1.006      1.072         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.6s\n",
            "                   all       1427      10955      0.749      0.737      0.829      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.48G     0.9407     0.9691      1.063         99        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.6s\n",
            "                   all       1427      10955      0.776      0.751      0.846      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15      10.1G     0.9326     0.9563      1.056         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.3s\n",
            "                   all       1427      10955      0.802      0.751       0.85      0.717\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/15      8.29G      0.862     0.9079      1.029         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 12.3s\n",
            "                   all       1427      10955      0.778      0.726      0.826      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/15      8.16G     0.8335      0.837      1.018         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.2it/s 1:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.0it/s 12.6s\n",
            "                   all       1427      10955      0.795      0.735      0.833      0.693\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 4, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "7 epochs completed in 0.170 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_8/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_8/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_8/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.3it/s 8.9s\n",
            "                   all       1427      10955      0.776      0.751      0.846      0.717\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 16:52:21,416] Trial 8 finished with value: 0.8460454929009547 and parameters: {'lr0': 2.575193453459791e-05, 'weight_decay': 0.00010843141695070005, 'optimizer': 'AdamW', 'degrees': 3.0436355788344622, 'translate': 0.03435502642011926, 'scale': 0.7143390431304664, 'hsv_s': 0.6537101657585801, 'hsv_v': 0.4768045506904003, 'fliplr': 0.101100754344642}. Best is trial 6 with value: 0.8850434832978041.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 9/15 completed\n",
            "   ‚è± Elapsed: 73.26 min | Est. remaining: 48.84 min\n",
            "   üìà Best mAP50 so far: 0.8850\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=4.992565942653441, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.3037196540738684, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.620346648827545, hsv_v=0.6070780011656236, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1.863479687890512e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_9, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_9, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.742643126478203, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.061368359303174205, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0031185513262935428, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1867.7¬±812.8 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 7.4Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 407.2¬±306.4 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 420.3Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=1.863479687890512e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0031185513262935428), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_9\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.16G      1.105      1.158      1.147         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.9s\n",
            "                   all       1427      10955      0.801      0.782      0.875      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.71G      1.058       1.08      1.125         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.5s\n",
            "                   all       1427      10955      0.792      0.798      0.874      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.49G      1.064       1.07      1.123         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.8s\n",
            "                   all       1427      10955      0.794      0.779      0.875      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.47G      1.046      1.052      1.115        101        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.1s\n",
            "                   all       1427      10955      0.796      0.785      0.875       0.71\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.103 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_9/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_9/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_9/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.5it/s 7.8s\n",
            "                   all       1427      10955        0.8       0.78      0.875      0.722\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.5ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 16:58:43,194] Trial 9 finished with value: 0.8750028274347469 and parameters: {'lr0': 1.863479687890512e-05, 'weight_decay': 0.0031185513262935428, 'optimizer': 'SGD', 'degrees': 4.992565942653441, 'translate': 0.061368359303174205, 'scale': 0.742643126478203, 'hsv_s': 0.620346648827545, 'hsv_v': 0.6070780011656236, 'fliplr': 0.3037196540738684}. Best is trial 6 with value: 0.8850434832978041.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 10/15 completed\n",
            "   ‚è± Elapsed: 79.63 min | Est. remaining: 39.81 min\n",
            "   üìà Best mAP50 so far: 0.8850\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=0.10445120798898033, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.4915300064020022, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6809781158663071, hsv_v=0.5688744498910444, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0002129034242461898, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_10, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8348840684582842, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0004607127707965328, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0014385954648881343, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1591.5¬±721.8 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 2.5Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 568.0¬±398.5 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 259.9Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0002129034242461898, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0014385954648881343), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_10\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.21G     0.9646      1.112      1.088         68        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.0s\n",
            "                   all       1427      10955      0.807      0.804      0.887      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.73G     0.9463      1.032      1.073         62        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.3s\n",
            "                   all       1427      10955      0.822      0.789      0.883      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.17G      0.949      1.023      1.071         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.1s\n",
            "                   all       1427      10955      0.802      0.797      0.883        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      10.1G     0.9316      1.003       1.06        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.9s\n",
            "                   all       1427      10955      0.799      0.797      0.882      0.796\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.105 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_10/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_10/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_10/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.5it/s 7.8s\n",
            "                   all       1427      10955      0.809      0.802      0.887      0.806\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 17:05:14,528] Trial 10 finished with value: 0.8874223638948902 and parameters: {'lr0': 0.0002129034242461898, 'weight_decay': 0.0014385954648881343, 'optimizer': 'SGD', 'degrees': 0.10445120798898033, 'translate': 0.0004607127707965328, 'scale': 0.8348840684582842, 'hsv_s': 0.6809781158663071, 'hsv_v': 0.5688744498910444, 'fliplr': 0.4915300064020022}. Best is trial 10 with value: 0.8874223638948902.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 11/15 completed\n",
            "   ‚è± Elapsed: 86.15 min | Est. remaining: 31.33 min\n",
            "   üìà Best mAP50 so far: 0.8874\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=0.02764936117365782, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.4892575963698931, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6916428565921124, hsv_v=0.5570867174474834, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00022142513713670634, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_11, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8251857262555127, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0005915162205970275, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0014768025882925554, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1589.3¬±656.0 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 5.1Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 728.7¬±397.2 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 468.4Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00022142513713670634, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0014768025882925554), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_11\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.19G     0.9623      1.108      1.088         68        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.9s\n",
            "                   all       1427      10955      0.811      0.797      0.888      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.73G     0.9408      1.026      1.071         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.8it/s 14.5s\n",
            "                   all       1427      10955      0.818      0.795      0.884      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.17G     0.9448      1.017       1.07         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.3s\n",
            "                   all       1427      10955       0.81      0.784      0.875      0.792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.54G     0.9287     0.9991       1.06        106        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.8it/s 15.4s\n",
            "                   all       1427      10955      0.798      0.795      0.873      0.788\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.106 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_11/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_11/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_11/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.3it/s 9.0s\n",
            "                   all       1427      10955       0.81      0.799      0.888      0.808\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 17:11:46,852] Trial 11 finished with value: 0.8881091835395264 and parameters: {'lr0': 0.00022142513713670634, 'weight_decay': 0.0014768025882925554, 'optimizer': 'SGD', 'degrees': 0.02764936117365782, 'translate': 0.0005915162205970275, 'scale': 0.8251857262555127, 'hsv_s': 0.6916428565921124, 'hsv_v': 0.5570867174474834, 'fliplr': 0.4892575963698931}. Best is trial 11 with value: 0.8881091835395264.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 12/15 completed\n",
            "   ‚è± Elapsed: 92.69 min | Est. remaining: 23.17 min\n",
            "   üìà Best mAP50 so far: 0.8881\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=0.05812835799572251, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.4957062286649268, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.691080745852033, hsv_v=0.5692518890069621, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00026737483521459726, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_12, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_12, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8021484812391766, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0035764036446040495, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0012673627043074565, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1909.9¬±797.1 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 7.7Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 732.8¬±432.6 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 503.5Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00026737483521459726, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0012673627043074565), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_12\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.19G     0.9557      1.101      1.087         66        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.6s\n",
            "                   all       1427      10955      0.794      0.815      0.886      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.72G     0.9335      1.021      1.069         62        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.6s\n",
            "                   all       1427      10955      0.815      0.802      0.887      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.14G     0.9377      1.009      1.067         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.9s\n",
            "                   all       1427      10955      0.799      0.786      0.879      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.53G     0.9212     0.9937      1.057        104        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.8it/s 14.3s\n",
            "                   all       1427      10955      0.794      0.792      0.874      0.789\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.106 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_12/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_12/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_12/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.2it/s 9.8s\n",
            "                   all       1427      10955      0.798       0.81      0.887      0.808\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 17:18:20,375] Trial 12 finished with value: 0.8865805616317612 and parameters: {'lr0': 0.00026737483521459726, 'weight_decay': 0.0012673627043074565, 'optimizer': 'SGD', 'degrees': 0.05812835799572251, 'translate': 0.0035764036446040495, 'scale': 0.8021484812391766, 'hsv_s': 0.691080745852033, 'hsv_v': 0.5692518890069621, 'fliplr': 0.4957062286649268}. Best is trial 11 with value: 0.8881091835395264.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 13/15 completed\n",
            "   ‚è± Elapsed: 99.25 min | Est. remaining: 15.27 min\n",
            "   üìà Best mAP50 so far: 0.8881\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=0.13644917499562953, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.3839220549560274, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6905748958175771, hsv_v=0.4044942134790513, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00027926356598975205, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_13, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_13, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8326561730448047, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.000904673616974576, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.001727823848693769, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2071.1¬±893.0 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 8.7Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 636.9¬±305.1 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 496.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00027926356598975205, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001727823848693769), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_13\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15      9.21G     0.9558        1.1      1.085         68        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.5s\n",
            "                   all       1427      10955      0.808      0.799      0.889      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.73G     0.9369      1.021      1.068         62        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 12.8s\n",
            "                   all       1427      10955      0.816      0.792      0.888      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.17G     0.9396       1.01      1.066         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.0s\n",
            "                   all       1427      10955       0.81      0.784      0.881      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      10.1G      0.925     0.9932      1.056        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.8it/s 15.0s\n",
            "                   all       1427      10955      0.787      0.782      0.873      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/15      9.69G      0.919     0.9754      1.049         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.8it/s 14.9s\n",
            "                   all       1427      10955      0.805      0.782      0.873      0.789\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 2, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "5 epochs completed in 0.129 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_13/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_13/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_13/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.6it/s 7.7s\n",
            "                   all       1427      10955      0.816      0.792      0.888      0.808\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 17:26:16,785] Trial 13 finished with value: 0.888064046351472 and parameters: {'lr0': 0.00027926356598975205, 'weight_decay': 0.001727823848693769, 'optimizer': 'SGD', 'degrees': 0.13644917499562953, 'translate': 0.000904673616974576, 'scale': 0.8326561730448047, 'hsv_s': 0.6905748958175771, 'hsv_v': 0.4044942134790513, 'fliplr': 0.3839220549560274}. Best is trial 11 with value: 0.8881091835395264.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 14/15 completed\n",
            "   ‚è± Elapsed: 107.19 min | Est. remaining: 7.66 min\n",
            "   üìà Best mAP50 so far: 0.8881\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=0.962848924344557, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.3821475704194012, flipud=0.0, format=torchscript, fraction=1.0, freeze=True, half=False, hsv_h=0.015, hsv_s=0.6939828894885501, hsv_v=0.40737628858054126, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00039254651878206415, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=trial_14, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=3, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=optuna_yolo_fine_tune, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/optuna_yolo_fine_tune/trial_14, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.7691910594505441, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.014265842978098032, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.002112269394178678, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1431.5¬±656.5 MB/s, size: 63.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels.cache... 4972 images, 24 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 3.6Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 673.4¬±191.0 MB/s, size: 56.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels.cache... 1421 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 457.0Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00039254651878206415, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.002112269394178678), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/optuna_yolo_fine_tune/trial_14\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/15       9.2G      0.947      1.085      1.087         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 0.9it/s 1:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.1s\n",
            "                   all       1427      10955      0.811      0.794       0.89      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/15      8.73G     0.9218     0.9998      1.066         61        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.1it/s 1:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.3s\n",
            "                   all       1427      10955      0.807      0.794      0.881      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/15      9.52G     0.9254     0.9895       1.06         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 13.3s\n",
            "                   all       1427      10955      0.801      0.788      0.868      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/15      9.49G      0.912      0.975      1.052        102        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 79/79 1.0it/s 1:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 0.9it/s 14.1s\n",
            "                   all       1427      10955      0.791       0.76       0.86      0.759\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 3 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=3) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "4 epochs completed in 0.104 hours.\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_14/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/optuna_yolo_fine_tune/trial_14/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/optuna_yolo_fine_tune/trial_14/weights/best.pt...\n",
            "Ultralytics 8.3.225 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.4it/s 8.3s\n",
            "                   all       1427      10955       0.81      0.795      0.889      0.805\n",
            "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 1.6ms postprocess per image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-04 17:32:43,976] Trial 14 finished with value: 0.8891296543012678 and parameters: {'lr0': 0.00039254651878206415, 'weight_decay': 0.002112269394178678, 'optimizer': 'SGD', 'degrees': 0.962848924344557, 'translate': 0.014265842978098032, 'scale': 0.7691910594505441, 'hsv_s': 0.6939828894885501, 'hsv_v': 0.40737628858054126, 'fliplr': 0.3821475704194012}. Best is trial 14 with value: 0.8891296543012678.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Trial 15/15 completed\n",
            "   ‚è± Elapsed: 113.64 min | Est. remaining: 0.00 min\n",
            "   üìà Best mAP50 so far: 0.8891\n",
            "\n",
            "==============================\n",
            "üèÜ BEST TRIAL SUMMARY üèÜ\n",
            "==============================\n",
            "   üïí Total time: 113.64 min\n",
            "   üìä Best mAP50: 0.8891\n",
            "   ‚öôÔ∏è Best Params:\n",
            "      lr0: 0.00039254651878206415\n",
            "      weight_decay: 0.002112269394178678\n",
            "      optimizer: SGD\n",
            "      degrees: 0.962848924344557\n",
            "      translate: 0.014265842978098032\n",
            "      scale: 0.7691910594505441\n",
            "      hsv_s: 0.6939828894885501\n",
            "      hsv_v: 0.40737628858054126\n",
            "      fliplr: 0.3821475704194012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a767b0be",
        "outputId": "590de7af-da4e-48de-e715-6a200970617d"
      },
      "source": [
        "!pip install optuna -q\n",
        "print(\"‚úÖ Optuna installed.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Optuna installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the best model"
      ],
      "metadata": {
        "id": "f6qTygLb_7EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "PROJECT_NAME = \"optuna_yolo_fine_tune\"\n",
        "DRIVE_FOLDER = '/content/drive/My Drive/VisionAssist-Models/'\n",
        "\n",
        "print(\"--- Starting Model Save ---\")\n",
        "\n",
        "try:\n",
        "    #  Get Best Trial Info\n",
        "    best_trial_num = study.best_trial.number\n",
        "    best_trial_value = study.best_trial.value\n",
        "    print(f\"‚úÖ Found best trial: Trial #{best_trial_num} with mAP50: {best_trial_value:.4f}\")\n",
        "\n",
        "    #  Define Paths\n",
        "    trained_model_path_colab = os.path.join(PROJECT_NAME, f\"trial_{best_trial_num}\", \"weights\", \"best.pt\")\n",
        "    model_save_name = f'yolov8n_optuna_trial{best_trial_num}_map{best_trial_value:.4f}.pt'\n",
        "    drive_save_path = os.path.join(DRIVE_FOLDER, model_save_name)\n",
        "\n",
        "    # Mount Drive\n",
        "    if not os.path.exists('/content/drive/My Drive'):\n",
        "         print(\"Mounting Google Drive...\")\n",
        "         drive.mount('/content/drive')\n",
        "    else:\n",
        "         print(\"Google Drive already mounted.\")\n",
        "\n",
        "    # Check if Model File Exists\n",
        "    if not os.path.exists(trained_model_path_colab):\n",
        "        print(f\"--- ‚õî ERROR: Model file not found at '{trained_model_path_colab}' ---\")\n",
        "        print(\"Please check the 'PROJECT_NAME' variable.\")\n",
        "    else:\n",
        "        #  Create Save Directory & Copy\n",
        "        print(f\"Ensuring save directory exists: {DRIVE_FOLDER}\")\n",
        "        os.makedirs(DRIVE_FOLDER, exist_ok=True)\n",
        "\n",
        "        print(f\"Copying '{trained_model_path_colab}' to '{drive_save_path}'...\")\n",
        "        shutil.copy(trained_model_path_colab, drive_save_path)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*30)\n",
        "        print(\"üèÜ SUCCESS! Model saved to Google Drive. üèÜ\")\n",
        "        print(f\"   Saved as: {model_save_name}\")\n",
        "        print(\"=\"*30)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"--- ‚õî AN ERROR OCCURRED: {e} ---\")\n",
        "    print(\"If you see 'study is not defined', you may have disconnected from the Colab runtime.\")"
      ],
      "metadata": {
        "id": "ckgjXp7L3R9l",
        "outputId": "310fe182-f9e9-4d43-8077-adb5671f2af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Model Save ---\n",
            "‚úÖ Found best trial: Trial #14 with mAP50: 0.8891\n",
            "Google Drive already mounted.\n",
            "Ensuring save directory exists: /content/drive/My Drive/VisionAssist-Models/\n",
            "Copying 'optuna_yolo_fine_tune/trial_14/weights/best.pt' to '/content/drive/My Drive/VisionAssist-Models/yolov8n_optuna_trial14_map0.8891.pt'...\n",
            "\n",
            "==============================\n",
            "üèÜ SUCCESS! Model saved to Google Drive. üèÜ\n",
            "   Saved as: yolov8n_optuna_trial14_map0.8891.pt\n",
            "==============================\n"
          ]
        }
      ]
    }
  ]
}