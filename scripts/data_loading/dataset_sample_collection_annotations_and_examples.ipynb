{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yf874x2EY4My",
        "outputId": "a6e51f98-42fa-46dc-ad7e-f001aaf194d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.209)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets pycocotools huggingface_hub pillow matplotlib pandas seaborn tqdm ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1IfWg0UY6XO",
        "outputId": "ca02118d-5d31-40dd-d2c1-0049f27ae787"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "WORKDIR = '/content/drive/MyDrive/M2-Dataset'\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "4f12qMctY7_t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnOTYPPPZO0f",
        "outputId": "4198ae92-784d-48f6-9c0d-104daca93706"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\n",
            "DSAI-M2\n",
            "project_dataset_sample\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create_coco_sample.py\n",
        "import json, os, random, shutil, requests, zipfile, io\n",
        "from tqdm import tqdm\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "ANNOT_ZIP = os.path.join(WORKDIR, 'annotations_trainval2017.zip')\n",
        "ANNOT_DIR = os.path.join(WORKDIR, 'coco_annotations')\n",
        "SAMPLE_OUT_JSON = os.path.join(WORKDIR, 'instances_coco_sample.json')\n",
        "IMG_OUT_DIR = os.path.join(WORKDIR, 'images', 'coco_sample')\n",
        "os.makedirs(IMG_OUT_DIR, exist_ok=True)\n",
        "\n",
        "def download_annotations():\n",
        "    if not os.path.exists(ANNOT_ZIP):\n",
        "        url = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'\n",
        "        print(\"Downloading COCO annotations (240MB)...\")\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(ANNOT_ZIP, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                if chunk: f.write(chunk)\n",
        "    if not os.path.exists(ANNOT_DIR):\n",
        "        shutil.unpack_archive(ANNOT_ZIP, ANNOT_DIR)\n",
        "\n",
        "def sample_coco(coco_json_path, out_json_path, n_images=1000, seed=42, ensure_cat_ids=None):\n",
        "    random.seed(seed)\n",
        "    coco = json.load(open(coco_json_path,'r'))\n",
        "    images = coco['images']\n",
        "    anns = coco['annotations']\n",
        "    cats = coco['categories']\n",
        "\n",
        "    img_id_to_img = {img['id']:img for img in images}\n",
        "    img_id_to_anns = {}\n",
        "    for a in anns:\n",
        "        img_id_to_anns.setdefault(a['image_id'], []).append(a)\n",
        "\n",
        "    all_image_ids = list(img_id_to_img.keys())\n",
        "    selected = set()\n",
        "\n",
        "    if ensure_cat_ids:\n",
        "        cat_to_imgs = {}\n",
        "        for a in anns:\n",
        "            if a['category_id'] in ensure_cat_ids:\n",
        "                cat_to_imgs.setdefault(a['category_id'], set()).add(a['image_id'])\n",
        "        per_cat_quota = max(1, n_images // max(1,len(ensure_cat_ids)))\n",
        "        for cat, imgs in cat_to_imgs.items():\n",
        "            imgs = list(imgs)\n",
        "            random.shuffle(imgs)\n",
        "            to_take = imgs[:per_cat_quota]\n",
        "            selected.update(to_take)\n",
        "\n",
        "    remaining = [i for i in all_image_ids if i not in selected]\n",
        "    random.shuffle(remaining)\n",
        "    to_add = n_images - len(selected)\n",
        "    if to_add > 0:\n",
        "        selected.update(remaining[:to_add])\n",
        "\n",
        "    sel_images = [img_id_to_img[i] for i in selected]\n",
        "    sel_anns = [a for a in anns if a['image_id'] in selected]\n",
        "    used_cat_ids = sorted({a['category_id'] for a in sel_anns})\n",
        "    sel_cats = [c for c in cats if c['id'] in used_cat_ids]\n",
        "\n",
        "    out = {'images': sel_images, 'annotations': sel_anns, 'categories': sel_cats}\n",
        "    json.dump(out, open(out_json_path,'w'), indent=2)\n",
        "    print(f\"Saved sample JSON with {len(sel_images)} images and {len(sel_anns)} annotations to {out_json_path}\")\n",
        "    return out\n",
        "\n",
        "def download_images_for_coco_sample(coco_sample_json, out_dir, retries=3):\n",
        "    coco = json.load(open(coco_sample_json,'r'))\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    for img in tqdm(coco['images']):\n",
        "        url = img.get('coco_url') or (\"http://images.cocodataset.org/train2017/\" + img['file_name'])\n",
        "        outp = os.path.join(out_dir, img['file_name'])\n",
        "        if os.path.exists(outp): continue\n",
        "        ok = False\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                r = requests.get(url, stream=True, timeout=20)\n",
        "                if r.status_code == 200:\n",
        "                    with open(outp,'wb') as f:\n",
        "                        for chunk in r.iter_content(1024):\n",
        "                            if chunk: f.write(chunk)\n",
        "                    ok = True\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                pass\n",
        "        if not ok:\n",
        "            print(\"Failed to download\", url)\n",
        "\n",
        "# run\n",
        "download_annotations()\n",
        "COCO_JSON = os.path.join(ANNOT_DIR, 'annotations', 'instances_train2017.json')\n",
        "sample_coco(COCO_JSON, SAMPLE_OUT_JSON, n_images=1000, seed=42)\n",
        "download_images_for_coco_sample(SAMPLE_OUT_JSON, IMG_OUT_DIR)\n",
        "print(\"COCO sample created at:\", SAMPLE_OUT_JSON)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7anNIA8s8D9",
        "outputId": "a6795d79-cd2b-42fe-cdc4-c6139f738f71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading COCO annotations (240MB)...\n",
            "Saved sample JSON with 1000 images and 7011 annotations to /content/M2-Dataset/instances_coco_sample.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [04:29<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COCO sample created at: /content/M2-Dataset/instances_coco_sample.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create_splits.py\n",
        "import json, os, random\n",
        "def create_splits(coco_path, out_dir, seed=42, ratios=(0.8,0.1,0.1)):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    coco = json.load(open(coco_path,'r'))\n",
        "    images = coco['images']\n",
        "    anns = coco['annotations']\n",
        "    cats = coco['categories']\n",
        "    random.seed(seed)\n",
        "    ids = [im['id'] for im in images]\n",
        "    random.shuffle(ids)\n",
        "    n = len(ids)\n",
        "    n_train = int(ratios[0]*n)\n",
        "    n_val = int(ratios[1]*n)\n",
        "    train_ids = set(ids[:n_train])\n",
        "    val_ids = set(ids[n_train:n_train+n_val])\n",
        "    test_ids = set(ids[n_train+n_val:])\n",
        "    def subset(idsset):\n",
        "        imgs = [i for i in images if i['id'] in idsset]\n",
        "        anns_sub = [a for a in anns if a['image_id'] in idsset]\n",
        "        used_cat_ids = sorted({a['category_id'] for a in anns_sub})\n",
        "        cats_sub = [c for c in cats if c['id'] in used_cat_ids]\n",
        "        return {'images':imgs,'annotations':anns_sub,'categories':cats_sub}\n",
        "    json.dump(subset(train_ids), open(os.path.join(out_dir,'instances_train.json'),'w'), indent=2)\n",
        "    json.dump(subset(val_ids), open(os.path.join(out_dir,'instances_val.json'),'w'), indent=2)\n",
        "    json.dump(subset(test_ids), open(os.path.join(out_dir,'instances_test.json'),'w'), indent=2)\n",
        "    # data.yaml\n",
        "    names = [c['name'] for c in cats]\n",
        "    data_yaml = {\n",
        "      'train': 'path/to/images/train',\n",
        "      'val': 'path/to/images/val',\n",
        "      'test': 'path/to/images/test',\n",
        "      'nc': len(names),\n",
        "      'names': names\n",
        "    }\n",
        "    import yaml\n",
        "    with open(os.path.join(out_dir,'data.yaml'),'w') as f:\n",
        "        yaml.safe_dump(data_yaml, f)\n",
        "    print(\"Splits created in\", out_dir)\n",
        "\n",
        "# example run\n",
        "create_splits(f'{WORKDIR}/instances_coco_sample.json', f'{WORKDIR}/processed')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQZF-i3JteHP",
        "outputId": "0395cce1-a35c-442c-9ec9-e7fbd6cf8796"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits created in /content/M2-Dataset/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7dS_Fzwbua8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
