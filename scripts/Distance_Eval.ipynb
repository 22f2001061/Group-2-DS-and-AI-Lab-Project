{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJSsJ4HUslr",
        "outputId": "16d7d7c5-a24b-4810-de49-89d1c07f99e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.227-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.227-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.227 ultralytics-thop-2.0.18\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "✅ All libraries imported.\n"
          ]
        }
      ],
      "source": [
        "# --- CELL 1: SETUP & IMPORTS ---\n",
        "# This cell installs and imports all required libraries.\n",
        "\n",
        "!pip install ultralytics pandas scikit-learn\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive, files\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import torch\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "SEED_VALUE = 42\n",
        "np.random.seed(SEED_VALUE)\n",
        "torch.manual_seed(SEED_VALUE)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED_VALUE)\n",
        "\n",
        "print(\"✅ All libraries imported.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 2: MOUNT DRIVE & LOAD MODELS ---\n",
        "# This cell mounts Google Drive to load your trained models.\n",
        "\n",
        "from google.colab import drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"✅ Drive mounted.\")\n",
        "\n",
        "# --- 1. Load your trained \"Tuned\" YOLO model from Drive ---\n",
        "MODEL_DRIVE_PATH = '/content/drive/My Drive/VisionAssist-Models/yolov8n_optuna_best.pt' # <-- Adjust this path if needed\n",
        "if not os.path.exists(MODEL_DRIVE_PATH):\n",
        "    print(f\"--- ⛔ ERROR: 'best.pt' not found at {MODEL_DRIVE_PATH} ---\")\n",
        "    raise FileNotFoundError(\"Trained YOLO model not found in Google Drive.\")\n",
        "else:\n",
        "    print(f\"Found Tuned model in Google Drive: {MODEL_DRIVE_PATH}\")\n",
        "\n",
        "yolo_model_tuned = YOLO(MODEL_DRIVE_PATH)\n",
        "print(\"✅ Tuned YOLO model loaded.\")\n",
        "\n",
        "# --- 2. Load the \"Baseline\" YOLO model ---\n",
        "print(\"Loading Baseline YOLO (yolov8n.pt)...\")\n",
        "yolo_model_baseline = YOLO('yolov8n.pt') # The default, untuned model\n",
        "print(\"✅ Baseline YOLO model loaded.\")\n",
        "\n",
        "print(\"✅ All models are ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbHb1RNTV_mX",
        "outputId": "db9bc7bd-b568-4d40-ebf5-919a4506352b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✅ Drive mounted.\n",
            "Found Tuned model in Google Drive: /content/drive/My Drive/VisionAssist-Models/yolov8n_optuna_best.pt\n",
            "✅ Tuned YOLO model loaded.\n",
            "Loading Baseline YOLO (yolov8n.pt)...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 76.8MB/s 0.1s\n",
            "✅ Baseline YOLO model loaded.\n",
            "✅ All models are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define the path to your KITTI data ---\n",
        "# (Adjust this if you used a different folder name)\n",
        "KITTI_TRAINING_PATH = '/content/drive/My Drive/KITTI_data/training'\n",
        "\n",
        "# --- Verify the paths ---\n",
        "kitti_image_dir = os.path.join(KITTI_TRAINING_PATH, 'image_2')\n",
        "kitti_label_dir = os.path.join(KITTI_TRAINING_PATH, 'label_2')\n",
        "\n",
        "if not os.path.exists(kitti_image_dir) or not os.path.exists(kitti_label_dir):\n",
        "    print(\"--- ⛔ ERROR: KITTI dataset not found at the expected location! ---\")\n",
        "    print(f\"Please check your paths. We looked for:\")\n",
        "    print(f\"- {kitti_image_dir}\")\n",
        "    print(f\"- {kitti_label_dir}\")\n",
        "    print(\"\\nPlease complete the manual download steps described above.\")\n",
        "else:\n",
        "    print(\"✅ KITTI dataset found!\")\n",
        "    print(f\"Images: {kitti_image_dir}\")\n",
        "    print(f\"Labels: {kitti_label_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeOCgzxlWBmr",
        "outputId": "091e2f83-68d5-4415-99a4-0c28aae2b53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KITTI dataset found!\n",
            "Images: /content/drive/My Drive/KITTI_data/training/image_2\n",
            "Labels: /content/drive/My Drive/KITTI_data/training/label_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 4: HELPER FUNCTIONS (PARSERS & HEURISTIC) ---\n",
        "\n",
        "def estimate_distance(box_height_px, object_real_height_m, focal_length_px):\n",
        "    \"\"\"Your heuristic formula.\"\"\"\n",
        "    if box_height_px <= 0: return float('inf')\n",
        "    return (object_real_height_m * focal_length_px) / box_height_px\n",
        "\n",
        "def parse_kitti_label(label_path):\n",
        "    \"\"\"\n",
        "    Parses a KITTI label file.\n",
        "    Each line: type, truncated, occluded, alpha, bbox_left, bbox_top,\n",
        "    bbox_right, bbox_bottom, dim_H, dim_W, dim_L, loc_X, loc_Y, loc_Z, rot_Y\n",
        "    \"\"\"\n",
        "    gt_objects = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(' ')\n",
        "            obj_type = parts[0].lower() # e.g., 'Car', 'Pedestrian'\n",
        "\n",
        "            # We only care about common classes your model knows\n",
        "            # Map KITTI 'Car' to YOLO 'car', 'Pedestrian' to 'person', etc.\n",
        "            if obj_type == 'car':\n",
        "                yolo_class_name = 'car'\n",
        "            elif obj_type == 'pedestrian':\n",
        "                yolo_class_name = 'person'\n",
        "            elif obj_type == 'cyclist':\n",
        "                yolo_class_name = 'bicycle'\n",
        "            else:\n",
        "                continue # Skip objects we don't care about (e.g., 'Tram')\n",
        "\n",
        "            gt_objects.append({\n",
        "                'class_name': yolo_class_name,\n",
        "                'bbox_2d': [float(p) for p in parts[4:8]], # [left, top, right, bottom]\n",
        "                'real_height_m': float(parts[8]),         # dimensions H\n",
        "                'true_distance_m': float(parts[13])       # location Z\n",
        "            })\n",
        "    return gt_objects\n",
        "\n",
        "def calculate_iou(boxA, boxB):\n",
        "    \"\"\"Calculates Intersection over Union (IoU) between two boxes.\"\"\"\n",
        "    # box format: [x1, y1, x2, y2]\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    return iou\n",
        "\n",
        "print(\"✅ Helper functions defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L8rXP8_dpX3",
        "outputId": "3a0bf554-8bc3-4d73-9546-9bf31ee532e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Helper functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 5: THE MAIN CALIBRATION FUNCTION (v2 - More Logging) ---\n",
        "# This version now logs box_height and real_height so we can calibrate.\n",
        "\n",
        "def run_kitti_calibration(yolo_model, kitti_path, focal_length, conf_thresh, iou_threshold=0.5):\n",
        "\n",
        "    print(f\"\\n--- Starting Calibration ---\")\n",
        "    print(f\"  Model: {yolo_model.ckpt_path}\")\n",
        "    print(f\"  Confidence: {conf_thresh}, Focal Length: {focal_length}px\")\n",
        "\n",
        "    image_dir = os.path.join(kitti_path, 'image_2')\n",
        "    label_dir = os.path.join(kitti_path, 'label_2')\n",
        "\n",
        "    # We will only test a sample (e.g., first 100 images)\n",
        "    image_files = sorted(os.listdir(image_dir))[:100]\n",
        "\n",
        "    yolo_class_names = yolo_model.names\n",
        "\n",
        "    comparison_results = [] # Store (true_dist, pred_dist)\n",
        "\n",
        "    for image_name in image_files:\n",
        "        if not image_name.endswith('.png'):\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        label_path = os.path.join(label_dir, image_name.replace('.png', '.txt'))\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        # 1. Get Ground Truth (GT) objects from label file\n",
        "        gt_objects = parse_kitti_label(label_path)\n",
        "\n",
        "        # 2. Get Predicted objects from YOLO\n",
        "        preds = yolo_model.predict(image_path, conf=conf_thresh, verbose=False)\n",
        "        pred_boxes = preds[0].boxes.cpu().numpy()\n",
        "\n",
        "        # 3. Match Predictions to Ground Truth using IoU\n",
        "        for gt_obj in gt_objects:\n",
        "            gt_bbox = gt_obj['bbox_2d']\n",
        "            best_iou = 0\n",
        "            best_match = None\n",
        "\n",
        "            for i in range(len(pred_boxes)):\n",
        "                pred_class_id = int(pred_boxes.cls[i])\n",
        "                pred_class_name = yolo_class_names[pred_class_id]\n",
        "\n",
        "                # Check if classes match\n",
        "                if pred_class_name == gt_obj['class_name']:\n",
        "                    pred_bbox = pred_boxes.xyxy[i]\n",
        "                    iou = calculate_iou(gt_bbox, pred_bbox)\n",
        "\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_match = pred_bbox\n",
        "\n",
        "            # 4. If we find a good match, log the distances\n",
        "            if best_iou > iou_threshold:\n",
        "                # Get the predicted box height\n",
        "                y1, y2 = best_match[1], best_match[3]\n",
        "                box_height_px = y2 - y1\n",
        "\n",
        "                # Get GT info\n",
        "                real_height_m = gt_obj['real_height_m']\n",
        "                true_distance_m = gt_obj['true_distance_m']\n",
        "\n",
        "                # Run your heuristic\n",
        "                predicted_distance = estimate_distance(box_height_px, real_height_m, focal_length)\n",
        "\n",
        "                # Log for MAE calculation\n",
        "                if predicted_distance != float('inf') and box_height_px > 0:\n",
        "                    comparison_results.append({\n",
        "                        'true_distance': true_distance_m,\n",
        "                        'predicted_distance': predicted_distance,\n",
        "                        'class': gt_obj['class_name'],\n",
        "                        'box_height_px': box_height_px,   # <-- NEW\n",
        "                        'real_height_m': real_height_m    # <-- NEW\n",
        "                    })\n",
        "\n",
        "    print(f\"--- Calibration Complete: Found {len(comparison_results)} matched objects. ---\")\n",
        "    return pd.DataFrame(comparison_results)\n",
        "\n",
        "print(\"✅ Calibration function (v2) defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMSCDuiWdsMM",
        "outputId": "8b8045ad-3a66-468e-8458-3fb8acb734ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Calibration function (v2) defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 6: RUN & ANALYZE RESULTS ---\n",
        "\n",
        "# Define your heuristic's focal length\n",
        "HEURISTIC_FOCAL_LENGTH = 1000\n",
        "\n",
        "# --- 1. Run Baseline Model ---\n",
        "baseline_results = run_kitti_calibration(\n",
        "    yolo_model=yolo_model_baseline,\n",
        "    kitti_path=KITTI_TRAINING_PATH,\n",
        "    focal_length=HEURISTIC_FOCAL_LENGTH,\n",
        "    conf_thresh=0.4 # Use baseline confidence\n",
        ")\n",
        "\n",
        "# --- 2. Run Tuned Model ---\n",
        "tuned_results = run_kitti_calibration(\n",
        "    yolo_model=yolo_model_tuned,\n",
        "    kitti_path=KITTI_TRAINING_PATH,\n",
        "    focal_length=HEURISTIC_FOCAL_LENGTH,\n",
        "    conf_thresh=0.3 # Use your tuned confidence\n",
        ")\n",
        "\n",
        "# --- 3. Calculate MAE ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- FINAL MAE COMPARISON ---\")\n",
        "print(f\" (Using {HEURISTIC_FOCAL_LENGTH}px focal length heuristic)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if not baseline_results.empty:\n",
        "    baseline_mae = mean_absolute_error(baseline_results['true_distance'], baseline_results['predicted_distance'])\n",
        "    print(f\"  Baseline (yolov8n.pt) MAE: {baseline_mae:.2f} meters\")\n",
        "else:\n",
        "    print(\"  Baseline (yolov8n.pt) MAE: N/A (No objects matched)\")\n",
        "\n",
        "if not tuned_results.empty:\n",
        "    tuned_mae = mean_absolute_error(tuned_results['true_distance'], tuned_results['predicted_distance'])\n",
        "    print(f\"  Tuned (best.pt) MAE:     {tuned_mae:.2f} meters\")\n",
        "else:\n",
        "    print(\"  Tuned (best.pt) MAE:     N/A (No objects matched)\")\n",
        "\n",
        "print(\"\\n(Lower MAE is better)\")\n",
        "\n",
        "# --- Show a sample of the results ---\n",
        "if not tuned_results.empty:\n",
        "    print(\"\\n--- Sample of Tuned Model's Results (in meters) ---\")\n",
        "    print(tuned_results.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV8v_uOBdvAo",
        "outputId": "80645e6d-f5c8-4631-c08f-c6384f205931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Calibration ---\n",
            "  Model: yolov8n.pt\n",
            "  Confidence: 0.4, Focal Length: 1000px\n",
            "--- Calibration Complete: Found 237 matched objects. ---\n",
            "\n",
            "--- Starting Calibration ---\n",
            "  Model: /content/drive/My Drive/VisionAssist-Models/yolov8n_optuna_best.pt\n",
            "  Confidence: 0.3, Focal Length: 1000px\n",
            "--- Calibration Complete: Found 260 matched objects. ---\n",
            "\n",
            "==================================================\n",
            "--- FINAL MAE COMPARISON ---\n",
            " (Using 1000px focal length heuristic)\n",
            "==================================================\n",
            "  Baseline (yolov8n.pt) MAE: 7.31 meters\n",
            "  Tuned (best.pt) MAE:     7.54 meters\n",
            "\n",
            "(Lower MAE is better)\n",
            "\n",
            "--- Sample of Tuned Model's Results (in meters) ---\n",
            "   true_distance  predicted_distance   class  box_height_px  real_height_m\n",
            "0           8.41           12.033261  person     157.064651           1.89\n",
            "1          58.49           84.990540     car      19.649246           1.67\n",
            "2          34.38           42.321938     car      33.316055           1.41\n",
            "3          13.22           15.900142     car      98.741257           1.57\n",
            "4          38.26           53.121014     car      28.049164           1.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 7: CALIBRATE FOCAL LENGTH ---\n",
        "!pip install scipy -q\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def find_best_focal_length(results_df):\n",
        "    \"\"\"\n",
        "    Finds the optimal focal length to minimize MAE.\n",
        "    \"\"\"\n",
        "    if results_df.empty:\n",
        "        return None, float('inf')\n",
        "\n",
        "    # Define the function to minimize\n",
        "    # 'f' is the focal_length we are trying to find\n",
        "    def calculate_mae_for_focal_length(f):\n",
        "        # We must use .values to avoid pandas index issues\n",
        "        # f[0] is because 'minimize' passes 'f' as an array\n",
        "        predicted_distances = (results_df['real_height_m'].values * f[0]) / results_df['box_height_px'].values\n",
        "\n",
        "        # Calculate MAE between our new predictions and the truth\n",
        "        mae = np.mean(np.abs(predicted_distances - results_df['true_distance'].values))\n",
        "        return mae\n",
        "\n",
        "    # Start with an initial guess (1000)\n",
        "    initial_guess = [1000.0]\n",
        "\n",
        "    # Run the optimization\n",
        "    result = minimize(calculate_mae_for_focal_length, initial_guess, method='Nelder-Mead')\n",
        "\n",
        "    if result.success:\n",
        "        best_focal_length = result.x[0]\n",
        "        min_mae = result.fun\n",
        "        return best_focal_length, min_mae\n",
        "    else:\n",
        "        return None, float('inf')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- CALIBRATING FOCAL LENGTH ---\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Calibrate using the data from the Tuned model (which has more detections)\n",
        "best_f, tuned_mae_calibrated = find_best_focal_length(tuned_results)\n",
        "\n",
        "if best_f:\n",
        "    print(f\"✅ Calibration Successful!\")\n",
        "    print(f\"  Your old guess was 1000px, which gave an MAE of {tuned_mae:.2f}m\")\n",
        "    print(f\"  The OPTIMAL focal length is: {best_f:.2f}px\")\n",
        "    print(f\"  This gives a NEW, CALIBRATED MAE of: {tuned_mae_calibrated:.2f}m\")\n",
        "\n",
        "    # Now, let's see what the Baseline MAE is using this *same* calibrated focal length\n",
        "    baseline_preds_calibrated = (baseline_results['real_height_m'] * best_f) / baseline_results['box_height_px']\n",
        "    baseline_mae_calibrated = mean_absolute_error(baseline_results['true_distance'], baseline_preds_calibrated)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"--- FINAL CALIBRATED RESULTS ---\")\n",
        "    print(f\"  Calibrated Baseline MAE: {baseline_mae_calibrated:.2f}m\")\n",
        "    print(f\"  Calibrated Tuned MAE:    {tuned_mae_calibrated:.2f}m\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(\"\\nThis is the comparison you should put in your report.\")\n",
        "\n",
        "else:\n",
        "    print(\"--- ⛔ Calibration failed. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zZg6WsVf4-7",
        "outputId": "fb6a8c0d-5ec9-4b85-efe6-4088c8e1672a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "--- CALIBRATING FOCAL LENGTH ---\n",
            "==================================================\n",
            "✅ Calibration Successful!\n",
            "  Your old guess was 1000px, which gave an MAE of 7.54m\n",
            "  The OPTIMAL focal length is: 762.99px\n",
            "  This gives a NEW, CALIBRATED MAE of: 2.38m\n",
            "\n",
            "==================================================\n",
            "--- FINAL CALIBRATED RESULTS ---\n",
            "  Calibrated Baseline MAE: 2.18m\n",
            "  Calibrated Tuned MAE:    2.38m\n",
            "==================================================\n",
            "\n",
            "This is the comparison you should put in your report.\n"
          ]
        }
      ]
    }
  ]
}