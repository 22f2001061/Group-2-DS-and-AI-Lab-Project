{"cells":[{"cell_type":"markdown","id":"e28bf945","metadata":{"id":"e28bf945"},"source":["\n","# YOLOv8 Model Comparison — Base vs Optuna Tuned\n","\n","**Goal:** Evaluate and compare two YOLOv8 models on the **same dataset** and produce publication-ready **quantitative** and **qualitative** results with graphs.\n","\n","**Inputs (place in the same folder as this notebook):**\n","- `bdd100k_images_10k.zip` — images archive\n","- `test_data_bbd_labels.zip` — labels + `data.yaml` (or modify the YAML generation cell)\n","- `yolov8n_custom_coco_best.pt` — Base model (trained on custom/coco)\n","- `yolov8n_optuna_best.pt` — Tuned model (Optuna)\n","\n","**What you get:**\n","- Validation metrics (mAP50, mAP50-95, Precision, Recall)\n","- Per-class AP table\n","- Confusion matrices\n","- Precision–Recall curves\n","- Side-by-side qualitative predictions\n","- A concise comparison report and saved plots\n"]},{"cell_type":"markdown","id":"cd2d5f0f","metadata":{"id":"cd2d5f0f"},"source":["## 1. Environment Setup"]},{"cell_type":"code","execution_count":null,"id":"933b3688","metadata":{"id":"933b3688","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d55c5d5f-2da5-4684-ec69-4892431192d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.226-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Collecting matplotlib\n","  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Collecting pandas\n","  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n","Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n","Downloading ultralytics-8.3.226-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n","Installing collected packages: scikit-learn, pandas, matplotlib, ultralytics-thop, ultralytics\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.6.1\n","    Uninstalling scikit-learn-1.6.1:\n","      Successfully uninstalled scikit-learn-1.6.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n"]}],"source":["\n","# If you're running in Colab, uncomment the next line to get GPU acceleration info\n","# !nvidia-smi\n","\n","# Install dependencies (uncomment to run)\n","# Note: In some environments ultralytics is preinstalled.\n","%pip install -U ultralytics matplotlib pandas scikit-learn opencv-python tqdm\n"]},{"cell_type":"markdown","id":"3c813ea0","metadata":{"id":"3c813ea0"},"source":["## 2. Imports & Global Config"]},{"cell_type":"code","execution_count":null,"id":"8bb2c38f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bb2c38f","executionInfo":{"status":"ok","timestamp":1762618347278,"user_tz":-330,"elapsed":20230,"user":{"displayName":"Balasurya K","userId":"16524726478890606051"}},"outputId":"5c675931-7797-4b6b-b15c-5c1200ef2015"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","✅ All paths set relative to your Google Drive Vision folder\n","ROOT: /content/drive/MyDrive/Vision\n"]}],"source":["from pathlib import Path\n","import os, random, numpy as np\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# ==== PATH CONFIGURATION (edit here if you move files) ====\n","ROOT = Path(\"/content/drive/MyDrive/Vision\")\n","\n","# Dataset archives\n","DATA_IMAGES_ZIP = ROOT / \"bdd100k_images_10k.zip\"\n","DATA_LABELS_ZIP = ROOT / \"test_data_bbd_labels.zip\"\n","\n","# Extracted dataset folder\n","DATA_ROOT = ROOT / \"data\"\n","DATA_YAML = DATA_ROOT / \"test_data_bbd_labels\" / \"data.yaml\"\n","\n","# YOLO model weights\n","BASE_WEIGHTS = ROOT / \"yolov8n_custom_coco_best.pt\"\n","TUNED_WEIGHTS = ROOT / \"yolov8n_optuna_best.pt\"\n","\n","# Comparison output directory\n","RUNS_DIR = ROOT / \"runs_compare\"\n","BASE_TAG = \"base\"\n","TUNED_TAG = \"tuned\"\n","\n","BASE_RUN = RUNS_DIR / f\"val_{BASE_TAG}\"\n","TUNED_RUN = RUNS_DIR / f\"val_{TUNED_TAG}\"\n","BASE_PRED = RUNS_DIR / f\"pred_{BASE_TAG}\"\n","TUNED_PRED = RUNS_DIR / f\"pred_{TUNED_TAG}\"\n","\n","# Other configs\n","N_QUAL = 24           # number of images for qualitative visualization\n","MAX_PER_ROW = 4       # images per row in grid\n","IMGSZ = 640           # image size\n","\n","print(\"✅ All paths set relative to your Google Drive Vision folder\")\n","print(\"ROOT:\", ROOT)\n"]},{"cell_type":"markdown","id":"cea9def6","metadata":{"id":"cea9def6"},"source":["## 3. Dataset Preparation"]},{"cell_type":"code","execution_count":null,"id":"8d9ccb3e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"8d9ccb3e","executionInfo":{"status":"error","timestamp":1762618350582,"user_tz":-330,"elapsed":863,"user":{"displayName":"Balasurya K","userId":"16524726478890606051"}},"outputId":"54469144-7ea0-4a93-d11a-468f27007a11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting images...\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'shutil' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-980876690.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bdd100k_images_10k/*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_IMAGES_ZIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Images already extracted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"]}],"source":["\n","# Unzip archives if not already extracted\n","DATA_ROOT.mkdir(parents=True, exist_ok=True)\n","\n","if Path(DATA_IMAGES_ZIP).exists():\n","    if not any(DATA_ROOT.glob(\"bdd100k_images_10k/*\")):\n","        print(\"Extracting images...\")\n","        shutil.unpack_archive(DATA_IMAGES_ZIP, DATA_ROOT)\n","    else:\n","        print(\"Images already extracted.\")\n","else:\n","    print(f\"WARNING: {DATA_IMAGES_ZIP} not found. Place it next to this notebook.\")\n","\n","if Path(DATA_LABELS_ZIP).exists():\n","    if not any(DATA_ROOT.glob(\"test_data_bbd_labels/*\")):\n","        print(\"Extracting labels...\")\n","        shutil.unpack_archive(DATA_LABELS_ZIP, DATA_ROOT)\n","    else:\n","        print(\"Labels already extracted.\")\n","else:\n","    print(f\"WARNING: {DATA_LABELS_ZIP} not found. Place it next to this notebook.\")\n","\n","print('Expected YAML:', DATA_YAML.resolve())\n","if not DATA_YAML.exists():\n","    print(\"\"\"\n","DATA YAML not found at the expected location.\n","- If your labels zip already has `data.yaml`, please update DATA_YAML.\n","- Otherwise, create a minimal YOLO data.yaml here.\n","\n","We'll generate a minimal template below. Edit class names/paths accordingly if needed.\n","\"\"\")\n"]},{"cell_type":"markdown","id":"413faff7","metadata":{"id":"413faff7"},"source":["### 3.1 (Optional) Generate a minimal `data.yaml` if missing"]},{"cell_type":"code","execution_count":null,"id":"a4771cfc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4771cfc","executionInfo":{"status":"ok","timestamp":1762608904849,"user_tz":-330,"elapsed":23,"user":{"displayName":"Balasurya K","userId":"16524726478890606051"}},"outputId":"2364c4ac-b919-4a5a-8704-0f7d9435d33c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Could not infer image directories. Please set DATA_YAML manually.\n"]}],"source":["\n","from textwrap import dedent\n","\n","def write_minimal_yaml(yaml_path: Path, images_dir: Path, labels_dir: Path, names):\n","    yaml_path.parent.mkdir(parents=True, exist_ok=True)\n","    content = dedent(f\"\"\"\n","    # Auto-generated minimal data.yaml — edit paths/names to match your dataset\n","    path: {yaml_path.parent.as_posix()}\n","    train: {images_dir.as_posix()}/train\n","    val: {images_dir.as_posix()}/val\n","    test: {images_dir.as_posix()}/test\n","    names: {names}\n","    \"\"\")\n","    yaml_path.write_text(content)\n","    return yaml_path\n","\n","if not DATA_YAML.exists():\n","    # Try to infer an images root; update these as per your extracted folder structure\n","    cand = list(DATA_ROOT.glob(\"bdd100k_images_10k/images\"))\n","    if cand:\n","        images_root = cand[0]\n","        # Example class list — replace with your actual classes\n","        class_names = [\"person\",\"car\",\"traffic light\",\"bus\",\"truck\",\"bike\",\"rider\"]\n","        DATA_YAML = write_minimal_yaml(DATA_YAML, images_root, images_root, class_names)\n","        print(\"Wrote a minimal YAML to:\", DATA_YAML.resolve())\n","    else:\n","        print(\"Could not infer image directories. Please set DATA_YAML manually.\")\n","else:\n","    print(\"YAML exists:\", DATA_YAML.resolve())\n"]},{"cell_type":"markdown","id":"57abeb23","metadata":{"id":"57abeb23"},"source":["## 4. Load Models"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTLWC0nVjZWf","executionInfo":{"status":"ok","timestamp":1762606928467,"user_tz":-330,"elapsed":2001,"user":{"displayName":"Balasurya K","userId":"16524726478890606051"}},"outputId":"57a33a6a-0622-46ce-c498-4971287c018d"},"id":"jTLWC0nVjZWf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"45329d59","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"45329d59","executionInfo":{"status":"error","timestamp":1762608971036,"user_tz":-330,"elapsed":37,"user":{"displayName":"Balasurya K","userId":"16524726478890606051"}},"outputId":"c89b8838-b8af-4c3a-8b61-0adfb3251191"},"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Missing data.yaml at /content/drive/MyDrive/Vision/data/test_data_bbd_labels/data.yaml","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3689338037.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Missing {BASE_WEIGHTS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTUNED_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Missing {TUNED_WEIGHTS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mDATA_YAML\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Missing data.yaml at {DATA_YAML}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mYOLO\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Missing data.yaml at /content/drive/MyDrive/Vision/data/test_data_bbd_labels/data.yaml"]}],"source":["\n","assert Path(BASE_WEIGHTS).exists(), f\"Missing {BASE_WEIGHTS}\"\n","assert Path(TUNED_WEIGHTS).exists(), f\"Missing {TUNED_WEIGHTS}\"\n","assert DATA_YAML.exists(), f\"Missing data.yaml at {DATA_YAML}\"\n","\n","base_model = YOLO(BASE_WEIGHTS) if YOLO else None\n","tuned_model = YOLO(TUNED_WEIGHTS) if YOLO else None\n","\n","print(\"Base model:\", BASE_WEIGHTS)\n","print(\"Tuned model:\", TUNED_WEIGHTS)\n"]},{"cell_type":"markdown","id":"f46e27c0","metadata":{"id":"f46e27c0"},"source":["## 5. Quantitative Evaluation (Validation)"]},{"cell_type":"code","execution_count":null,"id":"b479ffb9","metadata":{"id":"b479ffb9"},"outputs":[],"source":["\n","RUNS_DIR.mkdir(exist_ok=True, parents=True)\n","\n","def run_val(model, out_dir: Path, imgsz=640):\n","    out_dir.mkdir(exist_ok=True, parents=True)\n","    results = model.val(data=DATA_YAML.as_posix(), imgsz=imgsz, project=str(out_dir), name=\"val\", save_json=True, plots=True, verbose=True)\n","    # In ultralytics, results.box contains aggregate metrics\n","    return results\n","\n","results_base = run_val(base_model, BASE_RUN, imgsz=IMGSZ)\n","results_tuned = run_val(tuned_model, TUNED_RUN, imgsz=IMGSZ)\n","\n","print(\"Validation finished. Plots & JSON saved to:\", RUNS_DIR.resolve())\n"]},{"cell_type":"markdown","id":"2acd2371","metadata":{"id":"2acd2371"},"source":["### 5.1 Aggregate Metrics Table"]},{"cell_type":"code","execution_count":null,"id":"8904471e","metadata":{"id":"8904471e"},"outputs":[],"source":["\n","def to_row(tag, r):\n","    return dict(\n","        Model=tag,\n","        mAP50=float(getattr(r.box, 'map50', np.nan)),\n","        mAP50_95=float(getattr(r.box, 'map', np.nan)),\n","        Precision=float(getattr(r.box, 'p', np.nan)),\n","        Recall=float(getattr(r.box, 'r', np.nan)),\n","        # speed metrics (ms per image)\n","        Speed_pre=float(getattr(r.speed, 'preprocess', np.nan)),\n","        Speed_infer=float(getattr(r.speed, 'inference', np.nan)),\n","        Speed_post=float(getattr(r.speed, 'postprocess', np.nan)),\n","    )\n","\n","metrics_df = pd.DataFrame([\n","    to_row(\"Base (COCO)\", results_base),\n","    to_row(\"Optuna Tuned\", results_tuned)\n","])\n","\n","display(metrics_df)\n","metrics_df.to_csv(RUNS_DIR / \"comparison_metrics.csv\", index=False)\n"]},{"cell_type":"markdown","id":"fee96f3d","metadata":{"id":"fee96f3d"},"source":["### 5.2 Global Metric Comparison Plots"]},{"cell_type":"code","execution_count":null,"id":"0c2d7728","metadata":{"id":"0c2d7728"},"outputs":[],"source":["\n","def barplot(df, cols, title, out_png):\n","    ax = df.set_index(\"Model\")[cols].plot(kind=\"bar\")\n","    ax.set_title(title)\n","    ax.set_ylabel(\"Score\")\n","    plt.tight_layout()\n","    plt.savefig(out_png, bbox_inches=\"tight\")\n","    plt.show()\n","\n","barplot(metrics_df, [\"mAP50\",\"mAP50_95\",\"Precision\",\"Recall\"],\n","        \"YOLOv8 Model Performance Comparison\", RUNS_DIR / \"global_metrics.png\")\n"]},{"cell_type":"markdown","id":"90254247","metadata":{"id":"90254247"},"source":["### 5.3 Per-class AP Table & Plot"]},{"cell_type":"code","execution_count":null,"id":"25bbdcd3","metadata":{"id":"25bbdcd3"},"outputs":[],"source":["\n","def per_class_ap(results):\n","    # results.box.map_class is not a public API; instead use results.results_dict or JSON files.\n","    # We'll try to read the per-class AP from saved JSON (coco-style) if available.\n","    # Fallback: empty.\n","    per_class = {}\n","    for r in [results]:\n","        # Find the last results JSON inside out_dir\n","        out_dir = Path(r.save_dir) if hasattr(r, 'save_dir') else r.files.get('save_dir', Path('.'))\n","        jsons = sorted(Path(out_dir).glob('*.json'))\n","        if not jsons:\n","            continue\n","        # Try to parse COCO-style eval json summary if present\n","        # If not available, we'll skip.\n","    return pd.DataFrame()\n","\n","# Instead, as a practical approach for most users of ultralytics:\n","# We'll parse the text summary produced in results.txt (if exists) to extract per-class APs.\n","def parse_results_txt(results_dir: Path):\n","    txt = results_dir / \"val\" / \"results.txt\"\n","    if not txt.exists():\n","        # sometimes it's at <results_dir>/results.txt depending on version\n","        txt = results_dir / \"results.txt\"\n","    if not txt.exists():\n","        return None\n","    lines = txt.read_text().splitlines()\n","    # Heuristic parse: look for lines like \"class, AP50, AP50-95\" or similar\n","    rows = []\n","    for ln in lines:\n","        # Example (varies by version); adapt pattern as needed\n","        if \",\" in ln and \"all\" not in ln and \"metrics\" not in ln.lower():\n","            parts = [p.strip() for p in ln.split(\",\")]\n","            if len(parts) >= 3 and parts[0] and parts[1].replace('.','',1).isdigit():\n","                try:\n","                    rows.append(dict(Class=parts[0], AP50=float(parts[1]), AP50_95=float(parts[2])))\n","                except:\n","                    pass\n","    if rows:\n","        return pd.DataFrame(rows)\n","    return None\n","\n","base_pc = parse_results_txt(BASE_RUN)\n","tuned_pc = parse_results_txt(TUNED_RUN)\n","\n","if base_pc is not None and tuned_pc is not None:\n","    merged = base_pc.merge(tuned_pc, on=\"Class\", how=\"outer\", suffixes=(\" (Base)\",\" (Tuned)\")).fillna(0)\n","    display(merged.sort_values(\"Class\"))\n","    merged.to_csv(RUNS_DIR / \"per_class_ap_comparison.csv\", index=False)\n","\n","    # Plot AP50 per class (side-by-side)\n","    classes = merged[\"Class\"]\n","    x = np.arange(len(classes))\n","    width = 0.35\n","    fig = plt.figure()\n","    plt.bar(x - width/2, merged[\"AP50 (Base)\"], width, label=\"Base\")\n","    plt.bar(x + width/2, merged[\"AP50 (Tuned)\"], width, label=\"Tuned\")\n","    plt.xticks(x, classes, rotation=45, ha=\"right\")\n","    plt.title(\"Per-class AP50 Comparison\")\n","    plt.ylabel(\"AP50\")\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.savefig(RUNS_DIR / \"per_class_ap50.png\", bbox_inches=\"tight\")\n","    plt.show()\n","else:\n","    print(\"Per-class AP extraction skipped (could not parse results.txt).\")\n"]},{"cell_type":"markdown","id":"d6fd9742","metadata":{"id":"d6fd9742"},"source":["### 5.4 Confusion Matrices & PR Curves"]},{"cell_type":"code","execution_count":null,"id":"fe1722d9","metadata":{"id":"fe1722d9"},"outputs":[],"source":["\n","def show_if_exists(img_path: Path, title: str):\n","    if img_path.exists():\n","        from PIL import Image\n","        im = Image.open(img_path)\n","        plt.figure()\n","        plt.imshow(im)\n","        plt.axis('off')\n","        plt.title(title)\n","        plt.show()\n","    else:\n","        print(\"Missing:\", img_path)\n","\n","# Common file names produced by ultralytics val(plots=True)\n","show_if_exists(BASE_RUN / \"val\" / \"confusion_matrix.png\", \"Confusion Matrix — Base\")\n","show_if_exists(TUNED_RUN / \"val\" / \"confusion_matrix.png\", \"Confusion Matrix — Tuned\")\n","\n","show_if_exists(BASE_RUN / \"val\" / \"PR_curve.png\", \"PR Curve — Base\")\n","show_if_exists(TUNED_RUN / \"val\" / \"PR_curve.png\", \"PR Curve — Tuned\")\n"]},{"cell_type":"markdown","id":"18dfbbe8","metadata":{"id":"18dfbbe8"},"source":["## 6. Qualitative Comparison (Side-by-Side Predictions)"]},{"cell_type":"code","execution_count":null,"id":"3068fe72","metadata":{"id":"3068fe72"},"outputs":[],"source":["\n","# 6.1 Run predictions (same set of test images)\n","def pick_images(images_root: Path, n: int):\n","    imgs = []\n","    for sub in [\"test\",\"val\",\"images/test\",\"images/val\",\"images\"]:\n","        p = images_root / sub\n","        if p.exists():\n","            imgs.extend([*p.glob(\"*.jpg\"), *p.glob(\"*.png\")])\n","    random.shuffle(imgs)\n","    return imgs[:n]\n","\n","def run_predict(model, imgs, out_dir: Path, imgsz=640):\n","    out_dir.mkdir(parents=True, exist_ok=True)\n","    # Save visualizations\n","    model.predict(source=[str(p) for p in imgs], save=True, project=str(out_dir), name=\"pred\", imgsz=imgsz, conf=0.25, iou=0.45, verbose=False)\n","\n","# Attempt to infer an images root\n","images_roots = list(DATA_ROOT.glob(\"bdd100k_images_10k/images\"))\n","if images_roots:\n","    test_root = images_roots[0]\n","    sel_imgs = pick_images(test_root, N_QUAL if N_QUAL>0 else 0)\n","    print(\"Selected\", len(sel_imgs), \"images for qualitative viz\")\n","\n","    if sel_imgs:\n","        run_predict(base_model, sel_imgs, BASE_PRED, imgsz=IMGSZ)\n","        run_predict(tuned_model, sel_imgs, TUNED_PRED, imgsz=IMGSZ)\n","else:\n","    print(\"Could not find images root; qualitative step skipped.\")\n"]},{"cell_type":"markdown","id":"8306480d","metadata":{"id":"8306480d"},"source":["### 6.2 Build a Side-by-Side Grid"]},{"cell_type":"code","execution_count":null,"id":"d2292e81","metadata":{"id":"d2292e81"},"outputs":[],"source":["\n","from PIL import Image, ImageOps\n","\n","def collect_pred_images(pred_dir: Path):\n","    # Find rendered images produced by ultralytics (labels on image)\n","    cand = []\n","    for p in [pred_dir / \"pred\", pred_dir]:\n","        if p.exists():\n","            cand.extend([*p.glob(\"*.jpg\"), *p.glob(\"*.png\")])\n","    return sorted(cand)[:N_QUAL]\n","\n","def make_grid(imgs_left, imgs_right, out_png: Path, max_per_row=4, pad=4):\n","    assert len(imgs_left) == len(imgs_right), \"Left/right lists must align.\"\n","    pairs = list(zip(imgs_left, imgs_right))\n","    tiles = []\n","    # Build rows: [Base, Tuned] side-by-side per sample\n","    for left, right in pairs:\n","        L = Image.open(left).convert(\"RGB\")\n","        R = Image.open(right).convert(\"RGB\")\n","        # Same height padding\n","        H = max(L.height, R.height)\n","        L = ImageOps.pad(L, (L.width, H))\n","        R = ImageOps.pad(R, (R.width, H))\n","        combo = Image.new(\"RGB\", (L.width + R.width + pad, H), (255,255,255))\n","        combo.paste(L, (0,0))\n","        combo.paste(R, (L.width + pad, 0))\n","        tiles.append(combo)\n","\n","    # Determine grid layout\n","    rows = int(np.ceil(len(tiles)/max_per_row))\n","    colw = max(t.width for t in tiles)\n","    rowh = max(t.height for t in tiles)\n","    grid = Image.new(\"RGB\", (colw*max_per_row, rowh*rows), (255,255,255))\n","\n","    for idx, tile in enumerate(tiles):\n","        r, c = divmod(idx, max_per_row)\n","        grid.paste(tile, (c*colw, r*rowh))\n","\n","    out_png.parent.mkdir(parents=True, exist_ok=True)\n","    grid.save(out_png)\n","    return out_png\n","\n","if N_QUAL > 0 and (BASE_PRED.exists() and TUNED_PRED.exists()):\n","    left_imgs  = collect_pred_images(BASE_PRED / \"pred\")\n","    right_imgs = collect_pred_images(TUNED_PRED / \"pred\")\n","    if left_imgs and right_imgs and len(left_imgs)==len(right_imgs):\n","        out_grid = RUNS_DIR / \"qualitative_side_by_side.png\"\n","        make_grid(left_imgs, right_imgs, out_grid, max_per_row=MAX_PER_ROW)\n","        from IPython.display import Image as DispImage, display\n","        display(DispImage(filename=str(out_grid)))\n","    else:\n","        print(\"Qualitative grid skipped: prediction images not aligned/available.\")\n","else:\n","    print(\"Qualitative grid skipped.\")\n"]},{"cell_type":"markdown","id":"7c0cd0ad","metadata":{"id":"7c0cd0ad"},"source":["## 7. Error Analysis Summary"]},{"cell_type":"code","execution_count":null,"id":"cdada2b4","metadata":{"id":"cdada2b4"},"outputs":[],"source":["\n","# If available, we can summarize confusion matrices.\n","# For a rigorous programmatic analysis, parse underlying confusion matrix arrays if saved.\n","# As a practical approach, this notebook currently saves and shows them visually.\n","print(\"Review confusion matrices and PR curves above to identify common FP/FN patterns.\")\n"]},{"cell_type":"markdown","id":"de993914","metadata":{"id":"de993914"},"source":["## 8. Final Report"]},{"cell_type":"code","execution_count":null,"id":"3e32bc95","metadata":{"id":"3e32bc95"},"outputs":[],"source":["\n","report_lines = []\n","def line(s): report_lines.append(s)\n","\n","line(\"### Model Comparison — Summary\")\n","line(\"\")\n","line(metrics_df.to_markdown(index=False))\n","line(\"\")\n","line(\"- **Higher is better** for mAP50/mAP50-95/Precision/Recall.\")\n","line(\"- **Tuned** model should generally outperform **Base** if Optuna found stronger hyperparameters.\")\n","line(\"- Inspect per-class APs to see which categories benefit most.\")\n","line(\"- Review **Confusion Matrix** to spot common misclassifications and class imbalance effects.\")\n","line(\"- Review **PR Curves** to compare precision–recall tradeoffs.\")\n","line(\"- See the **side-by-side grid** for qualitative behavior differences.\")\n","\n","REPORT_MD = RUNS_DIR / \"FINAL_REPORT.md\"\n","RUNS_DIR.mkdir(exist_ok=True, parents=True)\n","REPORT_MD.write_text(\"\\n\".join(report_lines))\n","print(\"Saved report to\", REPORT_MD.resolve())\n"]},{"cell_type":"markdown","id":"8bf763e1","metadata":{"id":"8bf763e1"},"source":["## 9. Appendix — Training Curves (Optional)"]},{"cell_type":"code","execution_count":null,"id":"3c008a8a","metadata":{"id":"3c008a8a"},"outputs":[],"source":["\n","# If you have training runs (e.g., runs/detect/train/metrics.csv),\n","# point to them here to overlay learning curves (loss, mAP, precision, recall).\n","TRAIN_CSV_BASE  = Path(\"runs/detect/train_base/metrics.csv\")   # edit if available\n","TRAIN_CSV_TUNED = Path(\"runs/detect/train_tuned/metrics.csv\")  # edit if available\n","\n","def plot_training_curve(csv_path: Path, title: str, y_cols=('metrics/mAP50(B)','metrics/mAP50-95(B)')):\n","    if not csv_path.exists():\n","        print(\"Missing:\", csv_path)\n","        return\n","    df = pd.read_csv(csv_path)\n","    for col in y_cols:\n","        if col in df.columns:\n","            plt.plot(df.index, df[col], label=col)\n","    plt.title(title)\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Value\")\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_training_curve(TRAIN_CSV_BASE, \"Training Metrics — Base\")\n","plot_training_curve(TRAIN_CSV_TUNED, \"Training Metrics — Tuned\")\n"]},{"cell_type":"markdown","id":"e0f959e2","metadata":{"id":"e0f959e2"},"source":["\n","---\n","\n","### How to use\n","1. Put the four files next to this notebook: the two `.pt` weights and the two `.zip` archives.\n","2. Run the **Environment Setup** cell to install dependencies (if needed).\n","3. Run the notebook top-to-bottom. All outputs will be saved under `runs_compare/`.\n","4. If your dataset layout differs, update the `DATA_YAML` path or generate a minimal YAML in **3.1**.\n","\n","> This notebook is designed to mirror your previous \"compare_epochs\" workflow, but compares **two different models** on the **same dataset** with rich plots and a final report.\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}