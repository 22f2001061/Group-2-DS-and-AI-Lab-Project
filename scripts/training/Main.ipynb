{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "youtube_frames_path = \"/content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames\"\n",
        "\n",
        "if os.path.exists(youtube_frames_path):\n",
        "    print(f\"‚úÖ Google Drive mounted and YouTube frames folder found at: {youtube_frames_path}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è ERROR: Could not find YouTube frames folder at: {youtube_frames_path}\")\n",
        "    print(\"Please double-check the path and try mounting again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArRgJGc7sMdA",
        "outputId": "6586c1c5-3dc6-49a5-9ad4-d2a52006d28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted and YouTube frames folder found at: /content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "\n",
        "# --- Define Paths ---\n",
        "coco_zip_path = \"/content/drive/MyDrive/VisionAssist-Dataset/filtered_coco_data.zip\"\n",
        "unzip_destination = \"temp_coco_unzipped\" # Temporary folder in Colab\n",
        "\n",
        "# --- Check if Zip Exists ---\n",
        "if not os.path.exists(coco_zip_path):\n",
        "    print(f\"‚ö†Ô∏è ERROR: Cannot find the zip file at: {coco_zip_path}\")\n",
        "    print(\"Please make sure the file exists in your Google Drive.\")\n",
        "else:\n",
        "    # --- Unzip the File ---\n",
        "    print(f\"Unzipping '{os.path.basename(coco_zip_path)}' to '{unzip_destination}'...\")\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    os.makedirs(unzip_destination, exist_ok=True)\n",
        "    try:\n",
        "        with zipfile.ZipFile(coco_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(unzip_destination)\n",
        "        print(\"‚úÖ Unzipping complete.\")\n",
        "\n",
        "        potential_coco_data_folder = os.path.join(unzip_destination, \"yolo_data\")\n",
        "        if os.path.exists(os.path.join(potential_coco_data_folder, \"images\")):\n",
        "             actual_coco_data_folder = potential_coco_data_folder\n",
        "             print(f\"Found COCO data inside '{actual_coco_data_folder}'\")\n",
        "        elif os.path.exists(os.path.join(unzip_destination, \"images\")):\n",
        "             actual_coco_data_folder = unzip_destination\n",
        "             print(f\"Found COCO data directly inside '{actual_coco_data_folder}'\")\n",
        "        else:\n",
        "             actual_coco_data_folder = None\n",
        "             print(f\"‚ö†Ô∏è ERROR: Could not find 'images' and 'labels' folders within '{unzip_destination}'.\")\n",
        "\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"‚ö†Ô∏è ERROR: The file '{coco_zip_path}' is not a valid zip file or is corrupted.\")\n",
        "        actual_coco_data_folder = None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è An error occurred during unzipping: {e}\")\n",
        "        actual_coco_data_folder = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZwL_PeQHF53",
        "outputId": "ea696859-a6a7-47ca-8b06-19f11c417c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping 'filtered_coco_data.zip' to 'temp_coco_unzipped'...\n",
            "‚úÖ Unzipping complete.\n",
            "Found COCO data directly inside 'temp_coco_unzipped'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# --- Define Paths ---\n",
        "if 'actual_coco_data_folder' not in locals() or actual_coco_data_folder is None:\n",
        "    print(\"‚ö†Ô∏è ERROR: 'actual_coco_data_folder' is not defined. Please run Cell 1 successfully first.\")\n",
        "else:\n",
        "    coco_data_folder = actual_coco_data_folder # Use the path found after unzipping\n",
        "    youtube_frames_folder = \"/content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames\" # Adjust if needed\n",
        "    master_dataset_folder = \"master_dataset\"\n",
        "    master_images_folder = os.path.join(master_dataset_folder, \"images\")\n",
        "    # master_labels_folder = os.path.join(master_dataset_folder, \"labels\") # We are not creating labels folder yet\n",
        "\n",
        "    # --- Create Master Folders ---\n",
        "    print(f\"\\nCreating master images folder at '{master_images_folder}'...\")\n",
        "    os.makedirs(master_images_folder, exist_ok=True)\n",
        "\n",
        "    coco_images_path = os.path.join(coco_data_folder, \"images\")\n",
        "    # coco_labels_path = os.path.join(coco_data_folder, \"labels\") # Path not needed\n",
        "\n",
        "    # ---  Only check for images path ---\n",
        "    if os.path.exists(coco_images_path):\n",
        "        print(f\"Copying images from '{coco_images_path}' to '{master_images_folder}'...\")\n",
        "        # Using copytree with dirs_exist_ok=True merges contents\n",
        "        shutil.copytree(coco_images_path, master_images_folder, dirs_exist_ok=True)\n",
        "        print(\"COCO images copied.\")\n",
        "\n",
        "    else:\n",
        "        # --- Error message adjusted ---\n",
        "        print(f\"‚ö†Ô∏è ERROR: Could not find COCO 'images' folder in '{coco_data_folder}'.\")\n",
        "\n",
        "    # --- Copy YouTube Frames ---\n",
        "    if os.path.exists(youtube_frames_folder):\n",
        "        print(f\"Copying images from '{youtube_frames_folder}' to '{master_images_folder}'...\")\n",
        "        copied_yt_count = 0\n",
        "        for filename in os.listdir(youtube_frames_folder):\n",
        "            source_file = os.path.join(youtube_frames_folder, filename)\n",
        "            if os.path.isfile(source_file) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                destination_file = os.path.join(master_images_folder, filename)\n",
        "                shutil.copy2(source_file, destination_file)\n",
        "                copied_yt_count += 1\n",
        "        print(f\"Copied {copied_yt_count} YouTube frame images.\")\n",
        "    else:\n",
        "         print(f\"‚ö†Ô∏è Skipping YouTube frames copy as folder '{youtube_frames_folder}' was not found.\")\n",
        "\n",
        "\n",
        "    # --- Verification ---\n",
        "    print(\"\\n--- Verification ---\")\n",
        "    try:\n",
        "        num_master_images = len(os.listdir(master_images_folder))\n",
        "        print(f\"Total images in '{master_images_folder}': {num_master_images}\")\n",
        "        print(\"\\n‚úÖ Master dataset folder with images created successfully.\")\n",
        "        print(f\"You can now point your YOLOv8 annotation script to the '{master_images_folder}'.\")\n",
        "        print(f\"Make sure your annotation script saves the *new* label files into a separate 'labels' folder (e.g., 'master_dataset/labels').\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Verification failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2nfarsqIk7I",
        "outputId": "264a554f-4ad1-4656-8e07-8d5cc2bcb294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating master images folder at 'master_dataset/images'...\n",
            "Copying images from 'temp_coco_unzipped/images' to 'master_dataset/images'...\n",
            "COCO images copied.\n",
            "Copying images from '/content/drive/MyDrive/VisionAssist-Dataset/Yt Frames /Example_4_frames' to 'master_dataset/images'...\n",
            "Copied 2138 YouTube frame images.\n",
            "\n",
            "--- Verification ---\n",
            "Total images in 'master_dataset/images': 7138\n",
            "\n",
            "‚úÖ Master dataset folder with images created successfully.\n",
            "You can now point your YOLOv8 annotation script to the 'master_dataset/images'.\n",
            "Make sure your annotation script saves the *new* label files into a separate 'labels' folder (e.g., 'master_dataset/labels').\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for Annotation\n",
        "\n",
        "# --- 1. Install Ultralytics ---\n",
        "!pip install ultralytics -q\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from tqdm import tqdm # Progress bar\n",
        "\n",
        "print(\"‚úÖ Ultralytics installed.\")\n",
        "\n",
        "# --- 2. Define Paths ---\n",
        "MASTER_IMAGES_FOLDER = \"/content/master_dataset/images\"\n",
        "MASTER_LABELS_FOLDER = \"/content/master_dataset/labels\" # Labels will be created/overwritten here\n",
        "\n",
        "# --- 3. Create Labels Folder ---\n",
        "os.makedirs(MASTER_LABELS_FOLDER, exist_ok=True)\n",
        "print(f\"Labels will be saved to: {MASTER_LABELS_FOLDER}\")\n",
        "\n",
        "# --- 4. Load YOLOv8 Model for Annotation ---\n",
        "ANNOTATION_MODEL_NAME = 'yolov8n.pt'\n",
        "print(f\"Loading annotation model: {ANNOTATION_MODEL_NAME}...\")\n",
        "annotation_model = YOLO(ANNOTATION_MODEL_NAME)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "annotation_model.to(DEVICE)\n",
        "print(f\"Model loaded successfully on {DEVICE}.\")\n",
        "\n",
        "# --- 5. Class Mapping (REMOVED - Not needed for this approach) ---\n",
        "print(\"Will save labels for ALL detected COCO classes (0-79) using their original IDs.\")\n",
        "\n",
        "# --- 6. Get List of Images ---\n",
        "try:\n",
        "    # Gets all image files from the master images folder\n",
        "    image_files = [f for f in os.listdir(MASTER_IMAGES_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"\\nFound {len(image_files)} total images to annotate in {MASTER_IMAGES_FOLDER}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- ERROR ---\")\n",
        "    print(f\"Could not find the image folder: {MASTER_IMAGES_FOLDER}\")\n",
        "    print(\"Please ensure the master_dataset folder was created correctly.\")\n",
        "    image_files = [] # Prevent crash\n",
        "\n",
        "# --- 7. Annotation Loop (Processes ALL Images) ---\n",
        "annotation_count = 0 # Counter for images where labels were successfully generated\n",
        "\n",
        "if image_files: # Only proceed if images were found\n",
        "    # Loop through every image file with a progress bar\n",
        "    for image_name in tqdm(image_files, desc=\"Annotating ALL Images\"):\n",
        "        image_path = os.path.join(MASTER_IMAGES_FOLDER, image_name)\n",
        "\n",
        "        # Define the path where the label file should be saved\n",
        "        label_name = os.path.splitext(image_name)[0] + \".txt\"\n",
        "        label_path = os.path.join(MASTER_LABELS_FOLDER, label_name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Predicts objects in the current image using the loaded model\n",
        "        results = annotation_model.predict(image_path, save=False, verbose=False, conf=0.25)\n",
        "\n",
        "        # --- Convert Results to YOLO TXT Format and Save ---\n",
        "        # Checks if the prediction found any objects\n",
        "        if results and len(results[0].boxes) > 0:\n",
        "            lines_written = 0\n",
        "            # Opens the corresponding label file for writing (overwrites if it exists)\n",
        "            with open(label_path, 'w') as f:\n",
        "                # Iterates through each detected object (box)\n",
        "                for box in results[0].boxes:\n",
        "                    # Gets the original COCO class ID (0-79)\n",
        "                    coco_class_id = int(box.cls)\n",
        "\n",
        "                    # Gets normalized coordinates [center_x, center_y, width, height]\n",
        "                    x_center, y_center, width, height = box.xywhn[0].tolist()\n",
        "\n",
        "                    # Writes the label line using the original COCO ID\n",
        "                    f.write(f\"{coco_class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "                    lines_written += 1 # Count line written\n",
        "\n",
        "            # If we wrote labels to the file, increment the success counter\n",
        "            if lines_written > 0:\n",
        "                 annotation_count += 1\n",
        "            # If no objects were detected (lines_written == 0),\n",
        "            # but an empty file was created, remove the empty file.\n",
        "            elif os.path.exists(label_path):\n",
        "                 try: # Add error handling just in case\n",
        "                     if os.path.getsize(label_path) == 0:\n",
        "                          os.remove(label_path)\n",
        "                 except OSError:\n",
        "                      pass # Ignore error if file is already gone etc.\n",
        "\n",
        "        # else: # No detections made by the model for this image\n",
        "            # No label file needed or created.\n",
        "\n",
        "    # --- Final Summary ---\n",
        "    print(f\"\\n--- Annotation Summary ---\")\n",
        "    print(f\"Processed {len(image_files)} images.\")\n",
        "    print(f\"Generated or overwrote labels for {annotation_count} images.\")\n",
        "    print(f\"Labels were saved using original COCO class IDs (0-79).\")\n",
        "    print(f\"All labels are now saved in: {MASTER_LABELS_FOLDER}\")\n",
        "else:\n",
        "    # Message if the image folder was empty or not found\n",
        "    print(\"No images found to process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtqfMo1VZPdx",
        "outputId": "1a36fc96-11ca-45ba-b506-21db92df14c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ Ultralytics installed.\n",
            "Labels will be saved to: /content/master_dataset/labels\n",
            "Loading annotation model: yolov8n.pt...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 243.8MB/s 0.0s\n",
            "Model loaded successfully on cuda.\n",
            "Will save labels for ALL detected COCO classes (0-79) using their original IDs.\n",
            "\n",
            "Found 7138 total images to annotate in /content/master_dataset/images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Annotating ALL Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7138/7138 [02:11<00:00, 54.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Annotation Summary ---\n",
            "Processed 7138 images.\n",
            "Generated or overwrote labels for 7102 images.\n",
            "Labels were saved using original COCO class IDs (0-79).\n",
            "All labels are now saved in: /content/master_dataset/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset"
      ],
      "metadata": {
        "id": "dniQtoyyg7LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "MASTER_DATASET_FOLDER = \"master_dataset\" # Folder containing 'images' and 'labels'\n",
        "OUTPUT_FOLDER = \"split_dataset\"        # New folder where 'train', 'valid', 'test' will be created\n",
        "TRAIN_RATIO = 0.70                     # 70% for training\n",
        "VALID_RATIO = 0.20                     # 20% for validation\n",
        "TEST_RATIO = 0.10                      # 10% for testing\n",
        "\n",
        "# --- Sanity Check ---\n",
        "if abs(TRAIN_RATIO + VALID_RATIO + TEST_RATIO - 1.0) > 1e-6:\n",
        "    print(\"‚ö†Ô∏è ERROR: Ratios must add up to 1.0\")\n",
        "else:\n",
        "    # --- Define Input and Output Paths ---\n",
        "    images_input_dir = os.path.join(MASTER_DATASET_FOLDER, \"images\")\n",
        "    labels_input_dir = os.path.join(MASTER_DATASET_FOLDER, \"labels\")\n",
        "\n",
        "    train_images_dir = os.path.join(OUTPUT_FOLDER, \"train\", \"images\")\n",
        "    train_labels_dir = os.path.join(OUTPUT_FOLDER, \"train\", \"labels\")\n",
        "    valid_images_dir = os.path.join(OUTPUT_FOLDER, \"valid\", \"images\")\n",
        "    valid_labels_dir = os.path.join(OUTPUT_FOLDER, \"valid\", \"labels\")\n",
        "    test_images_dir = os.path.join(OUTPUT_FOLDER, \"test\", \"images\")\n",
        "    test_labels_dir = os.path.join(OUTPUT_FOLDER, \"test\", \"labels\")\n",
        "\n",
        "    # --- Create Output Directories ---\n",
        "    print(f\"Creating output directories in '{OUTPUT_FOLDER}'...\")\n",
        "    os.makedirs(train_images_dir, exist_ok=True)\n",
        "    os.makedirs(train_labels_dir, exist_ok=True)\n",
        "    os.makedirs(valid_images_dir, exist_ok=True)\n",
        "    os.makedirs(valid_labels_dir, exist_ok=True)\n",
        "    os.makedirs(test_images_dir, exist_ok=True)\n",
        "    os.makedirs(test_labels_dir, exist_ok=True)\n",
        "\n",
        "    # --- Get List of All Image Files ---\n",
        "    try:\n",
        "        all_images = [f for f in os.listdir(images_input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        if not all_images:\n",
        "             print(f\"‚ö†Ô∏è ERROR: No images found in '{images_input_dir}'.\")\n",
        "        else:\n",
        "             print(f\"Found {len(all_images)} images in '{images_input_dir}'.\")\n",
        "             # --- Shuffle the Images ---\n",
        "             random.shuffle(all_images)\n",
        "\n",
        "             # --- Calculate Split Indices ---\n",
        "             total_images = len(all_images)\n",
        "             train_end_idx = int(total_images * TRAIN_RATIO)\n",
        "             valid_end_idx = train_end_idx + int(total_images * VALID_RATIO)\n",
        "             # The rest go to test\n",
        "\n",
        "             # --- Define Splits ---\n",
        "             train_files = all_images[:train_end_idx]\n",
        "             valid_files = all_images[train_end_idx:valid_end_idx]\n",
        "             test_files = all_images[valid_end_idx:]\n",
        "\n",
        "             print(f\"Splitting into: {len(train_files)} Train, {len(valid_files)} Valid, {len(test_files)} Test\")\n",
        "\n",
        "             # --- Function to Copy Files ---\n",
        "             def copy_files(file_list, source_img_dir, source_lbl_dir, dest_img_dir, dest_lbl_dir):\n",
        "                 copied_count = 0\n",
        "                 for filename in tqdm(file_list, desc=f\"Copying to {os.path.basename(dest_img_dir)}\"):\n",
        "                     # Copy Image\n",
        "                     source_image_path = os.path.join(source_img_dir, filename)\n",
        "                     dest_image_path = os.path.join(dest_img_dir, filename)\n",
        "                     if os.path.exists(source_image_path):\n",
        "                         shutil.copy2(source_image_path, dest_image_path)\n",
        "\n",
        "                         # Copy Corresponding Label (if it exists)\n",
        "                         label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "                         source_label_path = os.path.join(source_lbl_dir, label_filename)\n",
        "                         dest_label_path = os.path.join(dest_lbl_dir, label_filename)\n",
        "                         if os.path.exists(source_label_path):\n",
        "                             shutil.copy2(source_label_path, dest_label_path)\n",
        "                         # else:\n",
        "                         #     print(f\"Warning: Label file not found for {filename}\") # Optional warning\n",
        "                         copied_count += 1\n",
        "                 return copied_count\n",
        "\n",
        "             # --- Perform the Copying ---\n",
        "             print(\"\\nCopying training files...\")\n",
        "             train_copied = copy_files(train_files, images_input_dir, labels_input_dir, train_images_dir, train_labels_dir)\n",
        "             print(f\"Copied {train_copied} training images and labels.\")\n",
        "\n",
        "             print(\"\\nCopying validation files...\")\n",
        "             valid_copied = copy_files(valid_files, images_input_dir, labels_input_dir, valid_images_dir, valid_labels_dir)\n",
        "             print(f\"Copied {valid_copied} validation images and labels.\")\n",
        "\n",
        "             print(\"\\nCopying test files...\")\n",
        "             test_copied = copy_files(test_files, images_input_dir, labels_input_dir, test_images_dir, test_labels_dir)\n",
        "             print(f\"Copied {test_copied} test images and labels.\")\n",
        "\n",
        "             print(\"\\n‚úÖ Dataset splitting complete!\")\n",
        "             print(f\"Split dataset is ready in the '{OUTPUT_FOLDER}' folder.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"--- ERROR ---\")\n",
        "        print(f\"Could not find the image folder: {images_input_dir}\")\n",
        "        print(\"Please ensure the master_dataset folder exists and contains images.\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- An unexpected error occurred: {e} ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbvzTBBYg--_",
        "outputId": "9c496e3f-c9ad-4a50-b469-f002eac20acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output directories in 'split_dataset'...\n",
            "Found 7138 images in 'master_dataset/images'.\n",
            "Splitting into: 4996 Train, 1427 Valid, 715 Test\n",
            "\n",
            "Copying training files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying to images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4996/4996 [00:01<00:00, 3575.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 4996 training images and labels.\n",
            "\n",
            "Copying validation files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying to images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1427/1427 [00:00<00:00, 3321.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 1427 validation images and labels.\n",
            "\n",
            "Copying test files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying to images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 715/715 [00:00<00:00, 2890.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 715 test images and labels.\n",
            "\n",
            "‚úÖ Dataset splitting complete!\n",
            "Split dataset is ready in the 'split_dataset' folder.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a data.yaml file\n"
      ],
      "metadata": {
        "id": "w1dNIFrchT9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile coco_custom_data.yaml\n",
        "# YAML configuration file for YOLOv8 training\n",
        "\n",
        "# Dataset paths: Relative paths to the split dataset folder\n",
        "# Assumes this yaml file is in /content/ and the data is in /content/split_dataset/\n",
        "train: ./split_dataset/train/images\n",
        "val: ./split_dataset/valid/images\n",
        "test: ./split_dataset/test/images # Optional: path to test images\n",
        "\n",
        "# Number of classes\n",
        "# Must be 80 since we used original COCO IDs during annotation\n",
        "nc: 80\n",
        "\n",
        "# Class names\n",
        "# Must be the standard 80 COCO class names in the correct order (0-79)\n",
        "names:\n",
        "  0: person\n",
        "  1: bicycle\n",
        "  2: car\n",
        "  3: motorcycle\n",
        "  4: airplane\n",
        "  5: bus\n",
        "  6: train\n",
        "  7: truck\n",
        "  8: boat\n",
        "  9: traffic light\n",
        "  10: fire hydrant\n",
        "  11: stop sign\n",
        "  12: parking meter\n",
        "  13: bench\n",
        "  14: bird\n",
        "  15: cat\n",
        "  16: dog\n",
        "  17: horse\n",
        "  18: sheep\n",
        "  19: cow\n",
        "  20: elephant\n",
        "  21: bear\n",
        "  22: zebra\n",
        "  23: giraffe\n",
        "  24: backpack\n",
        "  25: umbrella\n",
        "  26: handbag\n",
        "  27: tie\n",
        "  28: suitcase\n",
        "  29: frisbee\n",
        "  30: skis\n",
        "  31: snowboard\n",
        "  32: sports ball\n",
        "  33: kite\n",
        "  34: baseball bat\n",
        "  35: baseball glove\n",
        "  36: skateboard\n",
        "  37: surfboard\n",
        "  38: tennis racket\n",
        "  39: bottle\n",
        "  40: wine glass\n",
        "  41: cup\n",
        "  42: fork\n",
        "  43: knife\n",
        "  44: spoon\n",
        "  45: bowl\n",
        "  46: banana\n",
        "  47: apple\n",
        "  48: sandwich\n",
        "  49: orange\n",
        "  50: broccoli\n",
        "  51: carrot\n",
        "  52: hot dog\n",
        "  53: pizza\n",
        "  54: donut\n",
        "  55: cake\n",
        "  56: chair\n",
        "  57: couch\n",
        "  58: potted plant\n",
        "  59: bed\n",
        "  60: dining table\n",
        "  61: toilet\n",
        "  62: tv\n",
        "  63: laptop\n",
        "  64: mouse\n",
        "  65: remote\n",
        "  66: keyboard\n",
        "  67: cell phone\n",
        "  68: microwave\n",
        "  69: oven\n",
        "  70: toaster\n",
        "  71: sink\n",
        "  72: refrigerator\n",
        "  73: book\n",
        "  74: clock\n",
        "  75: vase\n",
        "  76: scissors\n",
        "  77: teddy bear\n",
        "  78: hair drier\n",
        "  79: toothbrush"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIkR_YfIhWRu",
        "outputId": "5bd2f866-1898-4ddd-8c57-26d70f51d395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing coco_custom_data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning"
      ],
      "metadata": {
        "id": "_gUemh0Ohi81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Start YOLOv8 Training ---\n",
        "\n",
        "!yolo task=detect mode=train \\\n",
        "model=yolov8n.pt \\\n",
        "data=coco_custom_data.yaml \\\n",
        "epochs=50 \\\n",
        "imgsz=640 \\\n",
        "name=yolov8n_custom_coco_run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_wKi4XfhkrD",
        "outputId": "7cbb07c1-b571-4321-bbab-0de1e8aa8121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.222 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco_custom_data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_custom_coco_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/yolov8n_custom_coco_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 150.0MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 292.4MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1721.9¬±1160.9 MB/s, size: 61.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/split_dataset/train/labels... 4971 images, 25 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4996/4996 2.4Kit/s 2.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/split_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 494.0¬±239.1 MB/s, size: 64.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/split_dataset/valid/labels... 1420 images, 7 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1427/1427 1.0Kit/s 1.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/split_dataset/valid/labels.cache\n",
            "Plotting labels to /content/runs/detect/yolov8n_custom_coco_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/yolov8n_custom_coco_run\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      2.86G     0.8752      1.047      1.078         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.6it/s 1:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.7it/s 12.3s\n",
            "                   all       1427      10862      0.778      0.737      0.836       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      3.95G     0.8546     0.9799      1.058         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.3it/s 10.6s\n",
            "                   all       1427      10862      0.741      0.721      0.805      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      3.98G     0.8594     0.9813      1.057         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.6it/s 9.8s\n",
            "                   all       1427      10862      0.702      0.679      0.767      0.658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      3.99G     0.8589     0.9779      1.053         69        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.0s\n",
            "                   all       1427      10862      0.715       0.67      0.746      0.638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      4.01G     0.8579     0.9691      1.052         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.7s\n",
            "                   all       1427      10862      0.696      0.664      0.746      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      4.02G     0.8463     0.9531      1.047         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.6s\n",
            "                   all       1427      10862      0.702      0.635      0.738      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      4.05G     0.8427     0.9402      1.045         82        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.5it/s 9.9s\n",
            "                   all       1427      10862      0.686       0.65      0.731       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      4.06G     0.8436     0.9332      1.047         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.0s\n",
            "                   all       1427      10862      0.689      0.676      0.742       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      4.09G     0.8398     0.9193      1.046         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 10.9s\n",
            "                   all       1427      10862      0.711       0.64       0.74      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      4.09G     0.8359     0.9111       1.04         66        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.3it/s 10.4s\n",
            "                   all       1427      10862       0.72      0.618       0.73       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      4.12G     0.8277     0.9021      1.037         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.7s\n",
            "                   all       1427      10862      0.688      0.648      0.723      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      4.14G     0.8243     0.8962      1.035         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 10.9s\n",
            "                   all       1427      10862      0.693      0.634      0.727      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      4.15G     0.8237     0.8926      1.035         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.6s\n",
            "                   all       1427      10862      0.699      0.631      0.723      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      4.16G     0.8209     0.8882      1.034         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.6s\n",
            "                   all       1427      10862      0.694      0.627      0.709      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      4.19G     0.8186     0.8755      1.029         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.5it/s 9.9s\n",
            "                   all       1427      10862      0.664       0.64      0.715      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      4.21G     0.8103     0.8637      1.026         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.7s\n",
            "                   all       1427      10862      0.706      0.621      0.723       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      4.23G     0.8147     0.8631      1.027         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.7s\n",
            "                   all       1427      10862      0.669      0.656      0.723      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      4.23G     0.8052     0.8522      1.023         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.6s\n",
            "                   all       1427      10862      0.677      0.646      0.726      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      4.26G      0.802     0.8472      1.023         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 10.9s\n",
            "                   all       1427      10862      0.685      0.625      0.726      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      4.28G     0.8062     0.8474      1.025         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.0s\n",
            "                   all       1427      10862      0.699      0.616      0.715      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50       4.3G      0.803     0.8423      1.021         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.0s\n",
            "                   all       1427      10862      0.698      0.626      0.723      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50       4.3G     0.7997     0.8352       1.02         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.6it/s 9.8s\n",
            "                   all       1427      10862      0.705      0.626      0.715      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      4.33G     0.7992     0.8346      1.021         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.0s\n",
            "                   all       1427      10862      0.696      0.634      0.716      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      4.35G     0.7932     0.8327      1.019         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.8s\n",
            "                   all       1427      10862       0.68      0.634      0.714      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      4.37G     0.7884     0.8242      1.016         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.5it/s 9.9s\n",
            "                   all       1427      10862      0.705      0.617      0.712      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      4.38G     0.7879     0.8155      1.015         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.4it/s 10.3s\n",
            "                   all       1427      10862      0.693      0.622      0.713      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50       4.4G     0.7901     0.8227      1.017         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.0it/s 11.2s\n",
            "                   all       1427      10862      0.687      0.631      0.711      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      4.42G     0.7843     0.8157      1.014         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.0s\n",
            "                   all       1427      10862      0.659      0.649      0.707      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      4.44G     0.7857     0.8061      1.012         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.4it/s 10.2s\n",
            "                   all       1427      10862      0.717      0.611      0.715      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      4.45G      0.788     0.8101      1.012         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.1s\n",
            "                   all       1427      10862      0.713      0.613       0.71      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      4.48G     0.7749     0.8014      1.009         67        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.8s\n",
            "                   all       1427      10862      0.691       0.63      0.713      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      4.49G     0.7762     0.7932      1.008         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.6it/s 9.7s\n",
            "                   all       1427      10862      0.751      0.591      0.717      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      4.51G     0.7761     0.7967      1.009         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.3it/s 10.4s\n",
            "                   all       1427      10862      0.735      0.602      0.714      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      4.52G     0.7725     0.7847      1.007         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.8s\n",
            "                   all       1427      10862      0.691      0.618       0.71      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      4.55G     0.7692      0.778      1.003         67        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.3it/s 10.4s\n",
            "                   all       1427      10862      0.699      0.624      0.719      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      4.57G     0.7705     0.7865      1.005         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.6s\n",
            "                   all       1427      10862      0.687      0.633      0.715      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      4.58G      0.772     0.7785      1.004        111        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.6it/s 9.7s\n",
            "                   all       1427      10862      0.699      0.625      0.715      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      4.59G     0.7651     0.7729      1.001         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 10.9s\n",
            "                   all       1427      10862      0.719      0.614      0.713      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      4.62G     0.7654     0.7768      1.004         56        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.7s\n",
            "                   all       1427      10862      0.697      0.634      0.718      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      4.64G      0.763     0.7723      1.002         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.7it/s 1:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.3it/s 10.4s\n",
            "                   all       1427      10862      0.708       0.62      0.721      0.608\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      4.65G     0.7277     0.7256     0.9719         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.8s\n",
            "                   all       1427      10862      0.707      0.586      0.689      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      4.66G     0.7026     0.6738      0.958         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.9it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.7s\n",
            "                   all       1427      10862      0.718      0.598      0.701      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      4.69G     0.6912     0.6661      0.952         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 4.0it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.8s\n",
            "                   all       1427      10862      0.691      0.627      0.703       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      4.71G       0.68     0.6489     0.9469         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.9it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.8it/s 9.4s\n",
            "                   all       1427      10862       0.71      0.615      0.704      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      4.73G     0.6813      0.646      0.949         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.9it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.3it/s 10.5s\n",
            "                   all       1427      10862      0.751      0.595       0.71      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      4.73G     0.6783     0.6402     0.9446         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 4.0it/s 1:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.6s\n",
            "                   all       1427      10862      0.739      0.603      0.707      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      4.76G     0.6766     0.6385      0.947         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.8it/s 1:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.1it/s 11.0s\n",
            "                   all       1427      10862      0.706      0.611      0.713      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      4.78G     0.6759     0.6348     0.9471         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 4.0it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.0it/s 11.2s\n",
            "                   all       1427      10862      0.719      0.609      0.709      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50       4.8G     0.6719     0.6333     0.9453         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 3.9it/s 1:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.6it/s 9.8s\n",
            "                   all       1427      10862      0.698      0.628      0.712      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50       4.8G     0.6725      0.634     0.9466         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 4.0it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 4.2it/s 10.8s\n",
            "                   all       1427      10862      0.709      0.616      0.711      0.602\n",
            "\n",
            "50 epochs completed in 1.300 hours.\n",
            "Optimizer stripped from /content/runs/detect/yolov8n_custom_coco_run/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/runs/detect/yolov8n_custom_coco_run/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/runs/detect/yolov8n_custom_coco_run/weights/best.pt...\n",
            "Ultralytics 8.3.222 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45/45 3.5it/s 12.9s\n",
            "                   all       1427      10862      0.777      0.737      0.836       0.75\n",
            "                person       1269       5537      0.907      0.899      0.959      0.871\n",
            "               bicycle         69        106      0.809      0.757      0.864      0.723\n",
            "                   car        427       1433      0.739      0.895       0.91       0.81\n",
            "            motorcycle        224        425      0.658      0.877      0.874      0.737\n",
            "              airplane         26         35      0.965      0.782      0.931      0.787\n",
            "                   bus        137        172      0.575      0.727      0.745      0.702\n",
            "                 train         40         54      0.898      0.648       0.87      0.749\n",
            "                 truck        250        353      0.689       0.85      0.847      0.778\n",
            "                  boat         32         44      0.711      0.818      0.813      0.704\n",
            "         traffic light         56         96      0.812      0.676      0.787      0.693\n",
            "          fire hydrant         12         12      0.935      0.917      0.984      0.951\n",
            "             stop sign          9          9      0.875      0.667       0.84      0.805\n",
            "         parking meter          7          7      0.657      0.714      0.724      0.683\n",
            "                 bench         40         49      0.888      0.488      0.761        0.6\n",
            "                  bird          6          7      0.476      0.571      0.615      0.594\n",
            "                   cat         15         16      0.814      0.812      0.925      0.828\n",
            "                   dog         32         47      0.627      0.532      0.661      0.614\n",
            "                 horse         32         69          1      0.787      0.943      0.844\n",
            "                 sheep          2         14      0.611      0.929      0.878      0.747\n",
            "                   cow         16         58      0.725      0.741      0.832       0.74\n",
            "              elephant         15         34      0.838       0.76      0.899      0.852\n",
            "                  bear          4          4      0.636          1      0.895      0.769\n",
            "                 zebra          3          9      0.861      0.692      0.886      0.802\n",
            "               giraffe          9         17          1      0.887      0.995       0.91\n",
            "              backpack         61         74      0.823      0.566      0.754      0.656\n",
            "              umbrella         88        167      0.803       0.76      0.862      0.766\n",
            "               handbag         45         60      0.785      0.367      0.646       0.56\n",
            "                   tie         36         58      0.682      0.638      0.775      0.673\n",
            "              suitcase         31         63      0.638      0.778      0.827      0.764\n",
            "               frisbee         35         40          1      0.912      0.956      0.905\n",
            "                  skis         31         43      0.792      0.837      0.865      0.691\n",
            "             snowboard         20         31      0.793      0.677      0.842      0.723\n",
            "           sports ball         40         44       0.94      0.707       0.92      0.856\n",
            "                  kite         32        138      0.705      0.942       0.93      0.828\n",
            "          baseball bat         25         34      0.794      0.765       0.89      0.675\n",
            "        baseball glove         29         38      0.923      0.944      0.961      0.889\n",
            "            skateboard         40         47      0.921      0.702      0.834      0.755\n",
            "             surfboard         37         64      0.779       0.75       0.83      0.682\n",
            "         tennis racket         42         60       0.86      0.783      0.903      0.762\n",
            "                bottle         57        110       0.93      0.723      0.895      0.793\n",
            "            wine glass         14         24      0.731       0.68      0.831      0.761\n",
            "                   cup         57        133      0.835      0.827      0.893      0.826\n",
            "                  fork          8         10      0.605        0.8      0.731      0.606\n",
            "                 knife         11         16      0.797      0.562      0.766      0.692\n",
            "                 spoon          8         11      0.633      0.318      0.799      0.754\n",
            "                  bowl         42         77      0.813      0.844      0.904      0.875\n",
            "                banana         10         20      0.723        0.6      0.722      0.683\n",
            "                 apple          4          7       0.51      0.571      0.653      0.549\n",
            "              sandwich         16         25      0.682      0.773      0.765      0.678\n",
            "                orange          4          7      0.532      0.857      0.747      0.733\n",
            "              broccoli          4         10      0.885      0.774      0.948      0.937\n",
            "               hot dog          6         40       0.93      0.332      0.747      0.634\n",
            "                 pizza         28         55      0.812        0.8      0.874       0.77\n",
            "                 donut         11         34      0.942      0.912      0.982      0.948\n",
            "                  cake         15         32      0.688      0.875      0.838      0.775\n",
            "                 chair         88        202      0.661      0.772      0.797      0.705\n",
            "                 couch         25         33      0.917      0.671      0.804      0.694\n",
            "          potted plant         23         28      0.744      0.623      0.666      0.577\n",
            "                   bed         15         16      0.738      0.625      0.693      0.662\n",
            "          dining table         70         80      0.782      0.887      0.923      0.805\n",
            "                toilet          4          6      0.936          1      0.995      0.955\n",
            "                    tv         35         43      0.919      0.721      0.894      0.825\n",
            "                laptop         25         38       0.78      0.868      0.912      0.836\n",
            "                 mouse          6          8      0.677      0.875      0.755      0.638\n",
            "                remote         29         42      0.966      0.675      0.898      0.772\n",
            "              keyboard          7         11      0.602      0.727      0.848      0.805\n",
            "            cell phone         21         25      0.644       0.48      0.644      0.576\n",
            "             microwave          5          5      0.709        0.8      0.906      0.805\n",
            "                  oven         13         20      0.794      0.773      0.899      0.837\n",
            "                  sink          6          8      0.506      0.625      0.697      0.654\n",
            "          refrigerator         11         13      0.688      0.923      0.861       0.82\n",
            "                  book         16         19      0.848      0.474      0.732      0.671\n",
            "                 clock         33         48       0.91      0.846      0.941      0.874\n",
            "                  vase         12         14      0.908      0.643      0.847      0.816\n",
            "            teddy bear         13         19      0.604      0.579      0.748      0.575\n",
            "            toothbrush          4          5       0.69        0.6      0.718      0.641\n",
            "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/yolov8n_custom_coco_run\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to Save Trained Model to Google Drive\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# --- Define Paths ---\n",
        "# Path where the training script saved the best model\n",
        "trained_model_path_colab = '/content/runs/detect/yolov8n_custom_coco_run/weights/best.pt'\n",
        "\n",
        "# Path where you want to save the model in Google Drive\n",
        "drive_save_folder = '/content/drive/My Drive/VisionAssist-Models/' # Example folder\n",
        "model_save_name = 'yolov8n_custom_coco_best.pt' # Choose a name for the saved model\n",
        "drive_save_path = os.path.join(drive_save_folder, model_save_name)\n",
        "\n",
        "# --- Mount Drive (if not already mounted) ---\n",
        "try:\n",
        "    if not os.path.exists('/content/drive/My Drive'):\n",
        "         print(\"Mounting Google Drive...\")\n",
        "         drive.mount('/content/drive')\n",
        "    else:\n",
        "         print(\"Google Drive already mounted.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting drive: {e}\")\n",
        "\n",
        "# --- Check if Model Exists ---\n",
        "if not os.path.exists(trained_model_path_colab):\n",
        "    print(f\"--- ERROR: Trained model not found at '{trained_model_path_colab}' ---\")\n",
        "    print(\"Please ensure training completed successfully and check the path.\")\n",
        "else:\n",
        "    # --- Create Save Directory in Drive ---\n",
        "    print(f\"Ensuring save directory exists: {drive_save_folder}\")\n",
        "    os.makedirs(drive_save_folder, exist_ok=True)\n",
        "\n",
        "    # --- Copy the Model ---\n",
        "    print(f\"Copying '{os.path.basename(trained_model_path_colab)}' to '{drive_save_path}'...\")\n",
        "    try:\n",
        "        shutil.copy(trained_model_path_colab, drive_save_path)\n",
        "        print(\"‚úÖ Model successfully saved to Google Drive.\")\n",
        "    except Exception as e:\n",
        "        print(f\"--- ERROR saving model to Drive: {e} ---\")"
      ],
      "metadata": {
        "id": "ckgjXp7L3R9l",
        "outputId": "08751a57-bdbe-4f54-e012-8c17981a9d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive already mounted.\n",
            "Ensuring save directory exists: /content/drive/My Drive/VisionAssist-Models/\n",
            "Copying 'best.pt' to '/content/drive/My Drive/VisionAssist-Models/yolov8n_custom_coco_best.pt'...\n",
            "‚úÖ Model successfully saved to Google Drive.\n"
          ]
        }
      ]
    }
  ]
}